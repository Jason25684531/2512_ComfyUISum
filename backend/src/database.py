"""
Database Module for Studio Core
æä¾› MySQL é€£æ¥æ± å’Œ Jobs è¡¨æ“ä½œ
"""
import os
import logging
from typing import Optional, List, Dict, Any
from datetime import datetime
import mysql.connector
from mysql.connector import pooling, Error

logger = logging.getLogger(__name__)


class Database:
    """MySQL è³‡æ–™åº«ç®¡ç†é¡"""
    
    def __init__(
        self,
        host: str,
        port: int,
        user: str,
        password: str,
        database: str,
        pool_name: str = "studio_pool",
        pool_size: int = 5
    ):
        """
        åˆå§‹åŒ–è³‡æ–™åº«é€£æ¥æ± 
        
        Args:
            host: MySQL ä¸»æ©Ÿä½å€
            port: MySQL ç«¯å£
            user: ç”¨æˆ¶å
            password: å¯†ç¢¼
            database: è³‡æ–™åº«åç¨±
            pool_name: é€£æ¥æ± åç¨±
            pool_size: é€£æ¥æ± å¤§å°
        """
        self.config = {
            "host": host,
            "port": port,
            "user": user,
            "password": password,
            "database": database,
            "pool_name": pool_name,
            "pool_size": pool_size,
            "pool_reset_session": True,
        }
        
        try:
            self.pool = pooling.MySQLConnectionPool(**self.config)
            logger.info(f"âœ“ MySQL é€£æ¥æ± å»ºç«‹æˆåŠŸ: {host}:{port}/{database}")
            self._init_schema()
        except Error as e:
            logger.error(f"âœ— MySQL é€£æ¥æ± å»ºç«‹å¤±æ•—: {e}")
            raise
    
    def _init_schema(self):
        """åˆå§‹åŒ–è³‡æ–™åº« Schema - å»ºç«‹ jobs å’Œ user_mapping è¡¨"""
        create_jobs_table_sql = """
        CREATE TABLE IF NOT EXISTS jobs (
            id VARCHAR(36) PRIMARY KEY,
            prompt TEXT,
            workflow VARCHAR(50),
            model VARCHAR(100),
            aspect_ratio VARCHAR(10),
            batch_size INT DEFAULT 1,
            seed INT DEFAULT -1,
            status VARCHAR(20),
            output_path TEXT,
            input_audio_path VARCHAR(255) DEFAULT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
            is_deleted BOOLEAN DEFAULT FALSE,
            INDEX idx_status (status),
            INDEX idx_created_at (created_at),
            INDEX idx_is_deleted (is_deleted)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
        """
        
        create_user_mapping_table_sql = """
        CREATE TABLE IF NOT EXISTS user_mapping (
            id INT PRIMARY KEY AUTO_INCREMENT,
            ip_address VARCHAR(45) UNIQUE NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            last_active TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
            INDEX idx_ip (ip_address),
            INDEX idx_last_active (last_active)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
        """
        
        try:
            conn = self.pool.get_connection()
            cursor = conn.cursor()
            cursor.execute(create_jobs_table_sql)
            cursor.execute(create_user_mapping_table_sql)
            conn.commit()
            logger.info("âœ“ Jobs å’Œ user_mapping è¡¨åˆå§‹åŒ–æˆåŠŸ")
        except Error as e:
            logger.error(f"âœ— å»ºç«‹è¡¨å¤±æ•—: {e}")
        finally:
            if conn.is_connected():
                cursor.close()
                conn.close()
    
    def insert_job(
        self,
        job_id: str,
        prompt: str,
        workflow: str,
        model: str,
        aspect_ratio: str = "1:1",
        batch_size: int = 1,
        seed: int = -1,
        status: str = "queued",
        input_audio_path: Optional[str] = None
    ) -> bool:
        """
        æ’å…¥æ–°ä»»å‹™è¨˜éŒ„
        
        Args:
            job_id: ä»»å‹™ ID (UUID)
            prompt: æç¤ºè©
            workflow: å·¥ä½œæµåç¨±
            model: æ¨¡å‹åç¨±
            aspect_ratio: åœ–ç‰‡æ¯”ä¾‹
            batch_size: æ‰¹æ¬¡å¤§å°
            seed: éš¨æ©Ÿç¨®å­
            status: ä»»å‹™ç‹€æ…‹
            input_audio_path: è¼¸å…¥éŸ³è¨Šæª”å (Phase 7 æ–°å¢)
        
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        sql = """
        INSERT INTO jobs (id, prompt, workflow, model, aspect_ratio, batch_size, seed, status, input_audio_path)
        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
        """
        
        try:
            conn = self.pool.get_connection()
            cursor = conn.cursor()
            cursor.execute(sql, (job_id, prompt, workflow, model, aspect_ratio, batch_size, seed, status, input_audio_path))
            conn.commit()
            logger.info(f"âœ“ ä»»å‹™è¨˜éŒ„æ’å…¥æˆåŠŸ: {job_id}")
            return True
        except Error as e:
            logger.error(f"âœ— æ’å…¥ä»»å‹™å¤±æ•—: {e}")
            return False
        finally:
            if conn.is_connected():
                cursor.close()
                conn.close()
    
    def update_job_status(
        self,
        job_id: str,
        status: str,
        output_path: Optional[str] = None
    ) -> bool:
        """
        æ›´æ–°ä»»å‹™ç‹€æ…‹
        
        Args:
            job_id: ä»»å‹™ ID
            status: æ–°ç‹€æ…‹ (finished, failed, cancelled)
            output_path: è¼¸å‡ºåœ–ç‰‡è·¯å¾‘ (å¤šå¼µç”¨é€—è™Ÿåˆ†éš”)
        
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        if output_path:
            sql = "UPDATE jobs SET status = %s, output_path = %s WHERE id = %s"
            params = (status, output_path, job_id)
        else:
            sql = "UPDATE jobs SET status = %s WHERE id = %s"
            params = (status, job_id)
        
        try:
            conn = self.pool.get_connection()
            cursor = conn.cursor()
            cursor.execute(sql, params)
            conn.commit()
            logger.info(f"âœ“ ä»»å‹™ç‹€æ…‹æ›´æ–°: {job_id} -> {status}")
            return True
        except Error as e:
            logger.error(f"âœ— æ›´æ–°ä»»å‹™ç‹€æ…‹å¤±æ•—: {e}")
            return False
        finally:
            if conn.is_connected():
                cursor.close()
                conn.close()
    
    def get_history(
        self,
        limit: int = 50,
        offset: int = 0,
        include_deleted: bool = False
    ) -> List[Dict[str, Any]]:
        """
        ç²å–æ­·å²è¨˜éŒ„
        
        Args:
            limit: è¿”å›æ•¸é‡
            offset: åç§»é‡
            include_deleted: æ˜¯å¦åŒ…å«å·²åˆªé™¤è¨˜éŒ„
        
        Returns:
            ä»»å‹™è¨˜éŒ„åˆ—è¡¨
        """
        where_clause = "" if include_deleted else "WHERE is_deleted = FALSE"
        sql = f"""
        SELECT id, prompt, workflow, model, aspect_ratio, batch_size, seed,
               status, output_path, created_at, updated_at
        FROM jobs
        {where_clause}
        ORDER BY created_at DESC
        LIMIT %s OFFSET %s
        """
        
        conn = None
        cursor = None
        try:
            conn = self.pool.get_connection()
            cursor = conn.cursor(dictionary=True)
            
            print(f"[DB DEBUG] åŸ·è¡Œ SQL æŸ¥è©¢ (limit={limit}, offset={offset})")
            print(f"[DB DEBUG] SQL: {sql.strip()[:200]}...")
            cursor.execute(sql, (limit, offset))
            results = cursor.fetchall()
            
            print(f"[DB DEBUG] fetchall() è¿”å› {len(results)} ç­†åŸå§‹è¨˜éŒ„")
            if results:
                print(f"[DB DEBUG] ç¬¬ä¸€ç­†: {results[0].get('id', 'N/A')}, status={results[0].get('status', 'N/A')}")
            
            logger.info(f"ğŸ” åŸ·è¡Œ SQL æŸ¥è©¢ (limit={limit}, offset={offset})")
            logger.info(f"ğŸ“ SQL: {sql.strip()}")
            logger.info(f"ğŸ“Š fetchall() è¿”å› {len(results)} ç­†åŸå§‹è¨˜éŒ„")
            
            # å°‡ datetime è½‰æ›ç‚º ISO å­—ä¸²
            for row in results:
                if row.get('created_at'):
                    row['created_at'] = row['created_at'].isoformat()
                if row.get('updated_at'):
                    row['updated_at'] = row['updated_at'].isoformat()
            
            logger.info(f"âœ“ æŸ¥è©¢æ­·å²è¨˜éŒ„: {len(results)} ç­†")
            return results
        except Error as e:
            logger.error(f"âœ— æŸ¥è©¢æ­·å²å¤±æ•—: {e}", exc_info=True)
            return []
        finally:
            if cursor:
                cursor.close()
            if conn and conn.is_connected():
                conn.close()
    
    def soft_delete_job(self, job_id: str) -> bool:
        """
        è»Ÿåˆªé™¤ä»»å‹™ (è¨­ç½® is_deleted = TRUE)
        
        Args:
            job_id: ä»»å‹™ ID
        
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        sql = "UPDATE jobs SET is_deleted = TRUE WHERE id = %s"
        
        try:
            conn = self.pool.get_connection()
            cursor = conn.cursor()
            cursor.execute(sql, (job_id,))
            conn.commit()
            logger.info(f"âœ“ ä»»å‹™å·²è»Ÿåˆªé™¤: {job_id}")
            return True
        except Error as e:
            logger.error(f"âœ— è»Ÿåˆªé™¤å¤±æ•—: {e}")
            return False
        finally:
            if conn.is_connected():
                cursor.close()
                conn.close()
    
    def soft_delete_by_output_path(self, output_filename: str) -> bool:
        """
        æ ¹æ“šè¼¸å‡ºæª”åè»Ÿåˆªé™¤ä»»å‹™
        
        Args:
            output_filename: è¼¸å‡ºæª”å (ä¾‹å¦‚: "abc123.png")
        
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        sql = "UPDATE jobs SET is_deleted = TRUE WHERE output_path LIKE %s"
        
        try:
            conn = self.pool.get_connection()
            cursor = conn.cursor()
            cursor.execute(sql, (f"%{output_filename}%",))
            affected_rows = cursor.rowcount
            conn.commit()
            
            if affected_rows > 0:
                logger.info(f"âœ“ å·²è»Ÿåˆªé™¤ {affected_rows} ç­†ä»»å‹™ (æª”å: {output_filename})")
            return True
        except Error as e:
            logger.error(f"âœ— æ ¹æ“šæª”åè»Ÿåˆªé™¤å¤±æ•—: {e}")
            return False
        finally:
            if conn.is_connected():
                cursor.close()
                conn.close()
    
    def get_or_create_user_id(self, ip_address: str) -> int:
        """
        æ ¹æ“š IP åœ°å€ç²å–æˆ–å»ºç«‹ç”¨æˆ¶ ID
        å¦‚æœ IP åœ°å€å·²å­˜åœ¨ï¼Œè¿”å›ç¾æœ‰çš„ç”¨æˆ¶ ID
        å¦‚æœ IP åœ°å€ä¸å­˜åœ¨ï¼Œå»ºç«‹æ–°çš„ç”¨æˆ¶ ID ä¸¦è¿”å›
        
        Args:
            ip_address: ç”¨æˆ¶çš„ IP åœ°å€
        
        Returns:
            ç”¨æˆ¶ ID (INT)
        """
        try:
            conn = self.pool.get_connection()
            cursor = conn.cursor(dictionary=True)
            
            # æŸ¥è©¢ç¾æœ‰ç”¨æˆ¶
            query_sql = "SELECT id FROM user_mapping WHERE ip_address = %s"
            cursor.execute(query_sql, (ip_address,))
            result = cursor.fetchone()
            
            if result:
                # æ›´æ–° last_active æ™‚é–“
                update_sql = "UPDATE user_mapping SET last_active = CURRENT_TIMESTAMP WHERE ip_address = %s"
                cursor.execute(update_sql, (ip_address,))
                conn.commit()
                return result['id']
            else:
                # å»ºç«‹æ–°ç”¨æˆ¶
                insert_sql = "INSERT INTO user_mapping (ip_address) VALUES (%s)"
                cursor.execute(insert_sql, (ip_address,))
                conn.commit()
                user_id = cursor.lastrowid
                logger.debug(f"âœ“ æ–°ç”¨æˆ¶å»ºç«‹: User #{user_id} ({ip_address})")
                return user_id
        except Error as e:
            logger.error(f"âœ— ç²å–æˆ–å»ºç«‹ç”¨æˆ¶ ID å¤±æ•—: {e}")
            return -1
        finally:
            if conn.is_connected():
                cursor.close()
                conn.close()
    
    def get_active_users_count(self) -> int:
        """
        ç²å–éå» 24 å°æ™‚å…§æ´»èºçš„ç”¨æˆ¶æ•¸
        
        Returns:
            æ´»èºç”¨æˆ¶æ•¸
        """
        try:
            conn = self.pool.get_connection()
            cursor = conn.cursor()
            sql = "SELECT COUNT(*) FROM user_mapping WHERE last_active >= DATE_SUB(NOW(), INTERVAL 24 HOUR)"
            cursor.execute(sql)
            result = cursor.fetchone()
            return result[0] if result else 0
        except Error as e:
            logger.error(f"âœ— æŸ¥è©¢æ´»èºç”¨æˆ¶å¤±æ•—: {e}")
            return 0
        finally:
            if conn.is_connected():
                cursor.close()
                conn.close()
    
    def check_connection(self) -> bool:
        """æª¢æŸ¥è³‡æ–™åº«é€£æ¥æ˜¯å¦æ­£å¸¸"""
        try:
            conn = self.pool.get_connection()
            cursor = conn.cursor()
            cursor.execute("SELECT 1")
            cursor.fetchone()
            return True
        except Error as e:
            logger.error(f"âœ— è³‡æ–™åº«é€£æ¥æª¢æŸ¥å¤±æ•—: {e}")
            return False
        finally:
            if conn.is_connected():
                cursor.close()
                conn.close()
