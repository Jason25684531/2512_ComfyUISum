"""
Backend API for Studio Core
æä¾›ä»»åŠ¡æäº¤å’ŒçŠ¶æ€æŸ¥è¯¢çš„æ¥å£
"""
import os
import json
import uuid
import logging
from logging.handlers import RotatingFileHandler
from datetime import datetime
from pathlib import Path
from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
from flask_limiter import Limiter
from flask_limiter.util import get_remote_address
from redis import Redis, RedisError
from werkzeug.utils import secure_filename

# ============================================
# è¼‰å…¥ .env ç’°å¢ƒè®Šæ•¸
# ============================================
def load_env():
    """è‡ªå‹•è¼‰å…¥å°ˆæ¡ˆæ ¹ç›®éŒ„çš„ .env æª”æ¡ˆ"""
    env_path = Path(__file__).parent.parent.parent / ".env"
    if env_path.exists():
        with open(env_path, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith("#") and "=" in line:
                    key, value = line.split("=", 1)
                    os.environ.setdefault(key.strip(), value.strip())
        print(f"âœ“ å·²è¼‰å…¥ .env æª”æ¡ˆ: {env_path}")

load_env()

# ============================================
# Configuration & Logging Setup
# ============================================
app = Flask(__name__)
CORS(app)

# åˆå§‹åŒ– Rate Limiter (ä½¿ç”¨ Redis ä½œç‚ºå„²å­˜å¾Œç«¯)
limiter = Limiter(
    app=app,
    key_func=get_remote_address,
    storage_uri=None,  # å°‡åœ¨å¾ŒçºŒè¨­ç½®
    # default_limits=["100 per hour"],
    default_limits=["10000 per hour"],  # <-- æ”¹æˆé€™æ¨£ï¼Œæˆ–è€…ç›´æ¥æ‹¿æ‰é€™è¡Œ
    storage_options={"socket_connect_timeout": 30},
    strategy="fixed-window"
)

# è¨­å®š CORS - å…è¨±æ‰€æœ‰ä¾†æºçš„è·¨åŸŸè«‹æ±‚
CORS(app, 
     origins=["*"],
     allow_headers=["Content-Type", "Authorization", "X-Requested-With"],
     methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
     supports_credentials=False)

# æ‰‹å‹•è™•ç† OPTIONS é æª¢è«‹æ±‚
@app.before_request
def handle_preflight():
    if request.method == "OPTIONS":
        response = app.make_default_options_response()
        response.headers["Access-Control-Allow-Origin"] = "*"
        response.headers["Access-Control-Allow-Methods"] = "GET, POST, PUT, DELETE, OPTIONS"
        response.headers["Access-Control-Allow-Headers"] = "Content-Type, Authorization, X-Requested-With"
        return response

@app.after_request
def after_request(response):
    response.headers["Access-Control-Allow-Origin"] = "*"
    response.headers["Access-Control-Allow-Methods"] = "GET, POST, PUT, DELETE, OPTIONS"
    response.headers["Access-Control-Allow-Headers"] = "Content-Type, Authorization, X-Requested-With"
    
    # è¨˜éŒ„è«‹æ±‚æ—¥èªŒ
    logger.info(f"{request.method} {request.path} - {response.status_code}")
    
    return response

# é…ç½®æ—¥å¿—è®°å½•å™¨ (ä½¿ç”¨ RotatingFileHandler)
log_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')

# ç¢ºä¿ logs ç›®éŒ„å­˜åœ¨
log_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', '..', 'logs')
os.makedirs(log_dir, exist_ok=True)
log_file = os.path.join(log_dir, 'backend.log')

# é…ç½® RotatingFileHandler (5MB, ä¿ç•™ 3 ä»½)
file_handler = RotatingFileHandler(
    log_file,
    maxBytes=5*1024*1024,  # 5MB
    backupCount=3,
    encoding='utf-8'
)
file_handler.setFormatter(log_formatter)
file_handler.setLevel(logging.INFO)

# é…ç½®æ§åˆ¶å°è¼¸å‡º
console_handler = logging.StreamHandler()
console_handler.setFormatter(log_formatter)
console_handler.setLevel(logging.INFO)

# é…ç½® root logger
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
logger.addHandler(file_handler)
logger.addHandler(console_handler)

# åŒæ™‚é…ç½® Flask app logger
app.logger.setLevel(logging.INFO)
app.logger.addHandler(file_handler)
app.logger.addHandler(console_handler)

# å¾ config è¼‰å…¥é…ç½®
from config import (
    REDIS_HOST, REDIS_PORT, REDIS_PASSWORD, JOB_QUEUE,
    STORAGE_OUTPUT_DIR
)
REDIS_QUEUE_NAME = JOB_QUEUE

# ============================================
# Database Connection Setup
# ============================================
from database import Database

# è¼‰å…¥è³‡æ–™åº«é…ç½®
DB_HOST = os.getenv("DB_HOST", "localhost")
DB_PORT = int(os.getenv("DB_PORT", 3306))
DB_USER = os.getenv("DB_USER", "studio_user")
DB_PASSWORD = os.getenv("DB_PASSWORD", "studio_password")
DB_NAME = os.getenv("DB_NAME", "studio_db")

# åˆå§‹åŒ–è³‡æ–™åº«é€£æ¥
db_client = None
try:
    db_client = Database(
        host=DB_HOST,
        port=DB_PORT,
        user=DB_USER,
        password=DB_PASSWORD,
        database=DB_NAME
    )
    logger.info(f"âœ“ è³‡æ–™åº«é€£æ¥æˆåŠŸ: {DB_HOST}:{DB_PORT}/{DB_NAME}")
except Exception as e:
    logger.warning(f"âš ï¸ è³‡æ–™åº«é€£æ¥å¤±æ•— (åŠŸèƒ½é™ç´š): {e}")

# ============================================
# Redis Connection Setup
# ============================================
try:
    redis_client = Redis(
        host=REDIS_HOST, 
        port=REDIS_PORT, 
        password=REDIS_PASSWORD,
        decode_responses=True
    )
    redis_client.ping()
    logger.info(f"âœ“ Redis è¿æ¥æˆåŠŸ: {REDIS_HOST}:{REDIS_PORT}")
    
    # é…ç½® Limiter ä½¿ç”¨ Redis
    limiter.storage_uri = f"redis://:{REDIS_PASSWORD}@{REDIS_HOST}:{REDIS_PORT}/1"
    
except RedisError as e:
    logger.error(f"âœ— Redis è¿æ¥å¤±è´¥: {e}")
    redis_client = None

# ============================================
# éŸ³è¨Šä¸Šå‚³è¨­å®š
# ============================================
ALLOWED_AUDIO_EXTENSIONS = {'.wav', '.mp3'}
UPLOAD_FOLDER = Path(__file__).parent.parent.parent / 'storage' / 'inputs'
UPLOAD_FOLDER.mkdir(parents=True, exist_ok=True)


# ============================================
# API Endpoints
# ============================================

@app.route('/api/upload', methods=['POST'])
@limiter.limit("30 per minute")
def upload_audio():
    """
    POST /api/upload
    ä¸Šå‚³éŸ³è¨Šæª”æ¡ˆ (æ”¯æ´ .wav, .mp3)
    
    Request: multipart/form-data, Key: 'file'
    
    Response:
    {
        "filename": "audio_550e8400-e29b.wav",
        "original_name": "æ—å¿—ç².wav"
    }
    """
    try:
        # 1. é©—è­‰æª”æ¡ˆæ˜¯å¦å­˜åœ¨
        if 'file' not in request.files:
            logger.warning("ä¸Šå‚³è«‹æ±‚ç¼ºå°‘ 'file' æ¬„ä½")
            return jsonify({'error': 'No file provided'}), 400
        
        file = request.files['file']
        
        if file.filename == '':
            logger.warning("ä¸Šå‚³çš„æª”æ¡ˆåç¨±ç‚ºç©º")
            return jsonify({'error': 'No file selected'}), 400
        
        # 2. é©—è­‰æª”æ¡ˆé¡å‹
        original_filename = secure_filename(file.filename)
        file_ext = os.path.splitext(original_filename)[1].lower()
        
        if file_ext not in ALLOWED_AUDIO_EXTENSIONS:
            logger.warning(f"ä¸æ”¯æ´çš„éŸ³è¨Šæ ¼å¼: {file_ext}")
            return jsonify({
                'error': f'Unsupported file type. Allowed: {", ".join(ALLOWED_AUDIO_EXTENSIONS)}'
            }), 400
        
        # 3. ç”Ÿæˆå”¯ä¸€æª”å (ä¿ç•™åŸå‰¯æª”å)
        unique_id = str(uuid.uuid4())[:12]
        new_filename = f"audio_{unique_id}{file_ext}"
        
        # 4. ç¢ºä¿å®‰å…¨çš„æª”å
        safe_filename = secure_filename(new_filename)
        
        # 5. å„²å­˜æª”æ¡ˆ
        file_path = UPLOAD_FOLDER / safe_filename
        
        try:
            file.save(str(file_path))
            logger.info(f"âœ… éŸ³è¨Šä¸Šå‚³æˆåŠŸ: {safe_filename} (åŸå§‹: {original_filename})")
        except PermissionError as e:
            logger.error(f"âŒ å„²å­˜æª”æ¡ˆæ¬Šé™ä¸è¶³: {e}")
            return jsonify({'error': 'Permission denied when saving file'}), 500
        except FileNotFoundError as e:
            logger.error(f"âŒ å„²å­˜è·¯å¾‘ä¸å­˜åœ¨: {e}")
            return jsonify({'error': 'Upload directory not found'}), 500
        
        # 6. å›å‚³çµæœ
        return jsonify({
            'filename': safe_filename,
            'original_name': file.filename  # ä½¿ç”¨åŸå§‹æª”åï¼ˆæœªç¶“ secure_filename è™•ç†ï¼‰
        }), 200
    
    except Exception as e:
        logger.error(f"âœ— upload æ¥å£ç•°å¸¸: {e}", exc_info=True)
        return jsonify({'error': 'Internal server error'}), 500


@app.route('/api/generate', methods=['POST', 'OPTIONS'])
@limiter.limit("10 per minute")
def generate():
    """
    POST /api/generate
    æ¥æ”¶ç”Ÿæˆè¯·æ±‚å¹¶å°†ä»»åŠ¡æ¨é€åˆ° Redis é˜Ÿåˆ—
    
    Request Body:
    {
        "prompt": "a cyberpunk cat",
        "seed": 12345,
        "workflow": "sdxl"
    }
    
    Response:
    {
        "job_id": "uuid...",
        "status": "queued"
    }
    """
    try:
        # 1. éªŒè¯è¯·æ±‚æ•°æ®
        data = request.get_json()
        if not data:
            logger.warning("è¯·æ±‚ç¼ºå°‘ JSON æ•°æ®")
            return jsonify({'error': 'Missing JSON data'}), 400
        
        prompt = data.get('prompt', '').strip()
        workflow = data.get('workflow', 'text_to_image')
        
        # ===== å®‰å…¨æ€§é©—è­‰ï¼šPrompt é•·åº¦é™åˆ¶ =====
        if len(prompt) > 1000:
            logger.warning(f"Prompt è¶…éé•·åº¦é™åˆ¶: {len(prompt)} > 1000")
            return jsonify({'error': 'Prompt exceeds maximum length of 1000 characters'}), 400
        
        # åªæœ‰ text_to_image éœ€è¦ prompt
        if workflow == 'text_to_image' and not prompt:
            logger.warning("text_to_image çš„ prompt å‚æ•°ä¸ºç©º")
            return jsonify({'error': 'prompt is required for text_to_image'}), 400
        
        # 2. ç”Ÿæˆå”¯ä¸€çš„ job_id
        job_id = str(uuid.uuid4())
        
        # 3. æ„é€ ä»»åŠ¡æ•°æ® (åŒ…å«æ‰€æœ‰å‰ç«¯å‚³ä¾†çš„åƒæ•¸)
        job_data = {
            'job_id': job_id,
            'prompt': prompt,
            'seed': data.get('seed', -1),  # -1 è¡¨ç¤ºéšæœº
            'workflow': data.get('workflow', 'text_to_image'),
            'model': data.get('model', 'turbo_fp8'),
            'aspect_ratio': data.get('aspect_ratio', '1:1'),
            'batch_size': data.get('batch_size', 1),
            'images': data.get('images', {}),  # Base64 åœ–ç‰‡å­—å…¸
            'audio': data.get('audio', ''),  # éŸ³è¨Šæª”å (virtual_human å·¥ä½œæµä½¿ç”¨)
            'created_at': datetime.now().isoformat()
        }
        
        # 4. æ¨é€åˆ° Redis é˜Ÿåˆ—
        if redis_client is None:
            logger.error("Redis å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return jsonify({'error': 'Redis service unavailable'}), 503
        
        redis_client.rpush(REDIS_QUEUE_NAME, json.dumps(job_data))
        logger.info(f"âœ“ ä»»åŠ¡å·²æ¨é€åˆ°é˜Ÿåˆ—: job_id={job_id}, prompt='{prompt}'")
        
        # 5. åˆå§‹åŒ–çŠ¶æ€ Hash
        status_key = f"job:status:{job_id}"
        redis_client.hset(status_key, mapping={
            'job_id': job_id,
            'status': 'queued',
            'progress': 0,
            'image_url': '',
            'error': '',
            'updated_at': datetime.now().isoformat()
        })
        redis_client.expire(status_key, 86400)  # 24å°æ—¶è¿‡æœŸ
        
        # 6. å¯«å…¥è³‡æ–™åº« (å¦‚æœè³‡æ–™åº«å¯ç”¨)
        if db_client:
            db_client.insert_job(
                job_id=job_id,
                prompt=prompt,
                workflow=workflow,
                model=job_data.get('model', 'turbo_fp8'),
                aspect_ratio=job_data.get('aspect_ratio', '1:1'),
                batch_size=job_data.get('batch_size', 1),
                seed=job_data.get('seed', -1),
                status='queued',
                input_audio_path=job_data.get('audio', None)  # Phase 7: è¨˜éŒ„éŸ³è¨Šæª”å
            )
        
        # 7. è¿”å›æˆåŠŸå“åº”
        return jsonify({
            'job_id': job_id,
            'status': 'queued'
        }), 202
    
    except Exception as e:
        logger.error(f"âœ— generate æ¥å£å¼‚å¸¸: {e}", exc_info=True)
        return jsonify({'error': 'Internal server error'}), 500


@app.route('/api/status/<job_id>', methods=['GET'])
@limiter.limit("2 per second")  # æ¯ç§’ 2 æ¬¡ = æ¯åˆ†é˜ 120 æ¬¡ï¼ˆå¯¬é¬†é™åˆ¶ï¼Œé©åˆè¼ªè©¢ï¼‰
def status(job_id):
    """
    GET /api/status/<job_id>
    æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
    
    Response:
    {
        "job_id": "...",
        "status": "processing",
        "progress": 50,
        "image_url": null,
        "error": ""
    }
    """
    try:
        if redis_client is None:
            logger.error("Redis å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return jsonify({'error': 'Redis service unavailable'}), 503
        
        # ä» Redis è¯»å–çŠ¶æ€
        status_key = f"job:status:{job_id}"
        job_status = redis_client.hgetall(status_key)
        
        if not job_status:
            logger.warning(f"ä»»åŠ¡ä¸å­˜åœ¨: job_id={job_id}")
            return jsonify({'error': 'Job not found'}), 404
        
        # å¦‚æœä»»å‹™å·²å®Œæˆä¸”è³‡æ–™åº«å¯ç”¨ï¼ŒåŒæ­¥ç‹€æ…‹åˆ°è³‡æ–™åº«
        current_status = job_status.get('status', 'unknown')
        if db_client and current_status in ['finished', 'failed', 'cancelled']:
            output_path = job_status.get('image_url', '')
            db_client.update_job_status(job_id, current_status, output_path)
        
        # è¿”å›çŠ¶æ€ä¿¡æ¯
        return jsonify({
            'job_id': job_status.get('job_id', job_id),
            'status': job_status.get('status', 'unknown'),
            'progress': int(job_status.get('progress', 0)),
            'image_url': job_status.get('image_url', ''),
            'error': job_status.get('error', '')
        }), 200
    
    except Exception as e:
        logger.error(f"âœ— status æ¥å£å¼‚å¸¸: {e}", exc_info=True)
        return jsonify({'error': 'Internal server error'}), 500


@app.route('/api/cancel/<job_id>', methods=['POST'])
def cancel_job(job_id):
    """
    POST /api/cancel/<job_id>
    å–æ¶ˆæ­£åœ¨åŸ·è¡Œçš„ä»»å‹™
    
    Response:
    {
        "success": true,
        "message": "Task cancelled"
    }
    """
    try:
        if redis_client is None:
            logger.error("Redis å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return jsonify({'error': 'Redis service unavailable'}), 503
        
        # æª¢æŸ¥ä»»å‹™æ˜¯å¦å­˜åœ¨
        status_key = f"job:status:{job_id}"
        job_status = redis_client.hgetall(status_key)
        
        if not job_status:
            logger.warning(f"ä»»å‹™ä¸å­˜åœ¨: job_id={job_id}")
            return jsonify({'error': 'Job not found'}), 404
        
        current_status = job_status.get('status', 'unknown')
        
        # å¦‚æœä»»å‹™å·²ç¶“å®Œæˆæˆ–å¤±æ•—ï¼Œç„¡æ³•å–æ¶ˆ
        if current_status in ['finished', 'failed', 'cancelled']:
            return jsonify({
                'success': False,
                'message': f'Cannot cancel job with status: {current_status}'
            }), 400
        
        # å°‡ç‹€æ…‹è¨­ç½®ç‚º cancelled
        redis_client.hset(status_key, 'status', 'cancelled')
        redis_client.hset(status_key, 'error', 'Task cancelled by user')
        
        logger.info(f"âœ“ ä»»å‹™å·²æ¨™è¨˜ç‚ºå–æ¶ˆ: job_id={job_id}")
        
        return jsonify({
            'success': True,
            'message': 'Task cancelled'
        }), 200
    
    except Exception as e:
        logger.error(f"âœ— cancel æ¥å£å¼‚å¸¸: {e}", exc_info=True)
        return jsonify({'error': 'Internal server error'}), 500


@app.route('/api/history', methods=['GET'])
def get_history():
    """
    GET /api/history?limit=50&offset=0
    ç²å–æ­·å²è¨˜éŒ„åˆ—è¡¨
    
    Query Parameters:
        limit: è¿”å›æ•¸é‡ (é è¨­ 50)
        offset: åç§»é‡ (é è¨­ 0)
    
    Response:
    {
        "total": 120,
        "limit": 50,
        "offset": 0,
        "jobs": [
            {
                "id": "uuid",
                "prompt": "...",
                "workflow": "text_to_image",
                "model": "turbo_fp8",
                "status": "finished",
                "output_path": "/outputs/xxx.png,/outputs/yyy.png",
                "created_at": "2024-12-31T10:00:00"
            }
        ]
    }
    """
    try:
        if db_client is None:
            logger.error("è³‡æ–™åº«æœªåˆå§‹åŒ–")
            return jsonify({'error': 'Database service unavailable'}), 503
        
        # è§£ææŸ¥è©¢åƒæ•¸
        limit = int(request.args.get('limit', 50))
        offset = int(request.args.get('offset', 0))
        
        # é™åˆ¶å–®æ¬¡æŸ¥è©¢æ•¸é‡
        limit = min(limit, 100)
        
        # å¾è³‡æ–™åº«ç²å–æ­·å²è¨˜éŒ„
        jobs = db_client.get_history(limit=limit, offset=offset)
        
        # è™•ç† output_pathï¼šè½‰æ›ç‚ºå‰ç«¯å¯è¨ªå•çš„ URL æ ¼å¼
        for job in jobs:
            output_path = job.get('output_path')
            if output_path:
                # å¦‚æœæ˜¯é€—è™Ÿåˆ†éš”çš„å¤šå€‹è·¯å¾‘ï¼Œè™•ç†æ¯ä¸€å€‹
                paths = output_path.split(',')
                # ç§»é™¤è·¯å¾‘å‰ç¶´ï¼Œåªä¿ç•™æª”åï¼Œä¸¦è½‰æ›ç‚º URL æ ¼å¼
                formatted_paths = []
                for path in paths:
                    path = path.strip()
                    if path:
                        # æå–æª”åï¼ˆç§»é™¤å¯èƒ½çš„è·¯å¾‘å‰ç¶´ï¼‰
                        filename = path.split('/')[-1].split('\\')[-1]
                        # è½‰æ›ç‚ºå®Œæ•´ URL
                        formatted_paths.append(f"/outputs/{filename}")
                # ç”¨é€—è™Ÿé€£æ¥æ‰€æœ‰è·¯å¾‘
                job['output_path'] = ','.join(formatted_paths) if formatted_paths else ''
        
        logger.info(f"âœ“ æŸ¥è©¢æ­·å²è¨˜éŒ„: {len(jobs)} ç­† (limit={limit}, offset={offset})")
        
        return jsonify({
            'total': len(jobs),  # ç°¡åŒ–ç‰ˆæœ¬ï¼Œå¯¦éš›å¯æŸ¥è©¢ç¸½æ•¸
            'limit': limit,
            'offset': offset,
            'jobs': jobs
        }), 200
    
    except Exception as e:
        logger.error(f"âœ— history æ¥å£å¼‚å¸¸: {e}", exc_info=True)
        return jsonify({'error': 'Internal server error'}), 500


@app.route('/api/metrics', methods=['GET'])
@limiter.limit("2 per second")  # æ¯ç§’ 2 æ¬¡ = æ¯åˆ†é˜ 120 æ¬¡ï¼ˆç›£æ§å„€è¡¨æ¿å°ˆç”¨ï¼‰
def metrics():
    """
    GET /api/metrics
    ç³»çµ±ç›£æ§æŒ‡æ¨™ç«¯é»ï¼ˆPhase 6 - é«˜é »è¼ªè©¢å°ˆç”¨ï¼‰
    
    Response:
    {
        "queue_length": 5,          // Redis ä½‡åˆ—ä¸­ç­‰å¾…çš„ä»»å‹™æ•¸é‡
        "worker_status": "online",  // Worker ç‹€æ…‹ (online/offline)
        "active_jobs": 2            // ç•¶å‰æ­£åœ¨è™•ç†çš„ä»»å‹™æ•¸é‡
    }
    """
    try:
        if redis_client is None:
            logger.error("Redis å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return jsonify({'error': 'Redis service unavailable'}), 503
        
        # 1. ç²å–ä½‡åˆ—é•·åº¦
        queue_length = redis_client.llen(REDIS_QUEUE_NAME)
        
        # 2. æª¢æŸ¥ Worker å¿ƒè·³ç‹€æ…‹
        worker_heartbeat = redis_client.get('worker:heartbeat')
        worker_status = 'online' if worker_heartbeat else 'offline'
        
        # 3. çµ±è¨ˆç•¶å‰æ­£åœ¨è™•ç†çš„ä»»å‹™ï¼ˆstatus='processing'ï¼‰
        active_jobs = 0
        # æƒææ‰€æœ‰ job:status:* éµ
        status_keys = redis_client.keys('job:status:*')
        for key in status_keys:
            job_status = redis_client.hget(key, 'status')
            if job_status == 'processing':
                active_jobs += 1
        
        logger.info(f"ğŸ“Š Metrics: queue={queue_length}, worker={worker_status}, active={active_jobs}")
        
        return jsonify({
            'queue_length': queue_length,
            'worker_status': worker_status,
            'active_jobs': active_jobs
        }), 200
    
    except Exception as e:
        logger.error(f"âœ— metrics æ¥å£å¼‚å¸¸: {e}", exc_info=True)
        return jsonify({'error': 'Internal server error'}), 500


@app.route('/health', methods=['GET'])
def health():
    """å¥åº·æ£€æŸ¥æ¥å£ - æª¢æŸ¥ Redis å’Œ MySQL ç‹€æ…‹"""
    redis_status = 'healthy' if redis_client and redis_client.ping() else 'unavailable'
    
    mysql_status = 'unavailable'
    if db_client:
        mysql_status = 'healthy' if db_client.check_connection() else 'error'
    
    overall_status = 'ok' if redis_status == 'healthy' else 'degraded'
    
    return jsonify({
        'status': overall_status,
        'redis': redis_status,
        'mysql': mysql_status
    }), 200


@app.route('/api/models', methods=['GET'])
def get_models():
    """
    GET /api/models
    æƒæ ComfyUI æ¨¡å‹ç›®éŒ„ï¼Œå›å‚³å¯ç”¨æ¨¡å‹åˆ—è¡¨
    
    Response:
    {
        "models": ["model1.safetensors", "model2.ckpt"],
        "unet_models": ["unet1.safetensors"]
    }
    """
    from config import COMFYUI_CHECKPOINTS_DIR, COMFYUI_UNET_DIR
    
    models = []
    unet_models = []
    
    # æƒæ Checkpoints ç›®éŒ„
    try:
        if COMFYUI_CHECKPOINTS_DIR.exists():
            for file_path in COMFYUI_CHECKPOINTS_DIR.rglob("*"):
                if file_path.is_file() and file_path.suffix.lower() in ['.safetensors', '.ckpt']:
                    # ä½¿ç”¨ç›¸å°è·¯å¾‘ï¼ˆç›¸å°æ–¼ checkpoints ç›®éŒ„ï¼‰
                    rel_path = file_path.relative_to(COMFYUI_CHECKPOINTS_DIR)
                    models.append(str(rel_path))
            logger.info(f"âœ“ æ‰¾åˆ° {len(models)} å€‹ Checkpoint æ¨¡å‹")
        else:
            logger.warning(f"Checkpoints ç›®éŒ„ä¸å­˜åœ¨: {COMFYUI_CHECKPOINTS_DIR}")
    except Exception as e:
        logger.error(f"æƒæ Checkpoints å¤±æ•—: {e}")
    
    # æƒæ UNET ç›®éŒ„
    try:
        if COMFYUI_UNET_DIR.exists():
            for file_path in COMFYUI_UNET_DIR.rglob("*"):
                if file_path.is_file() and file_path.suffix.lower() in ['.safetensors', '.ckpt', '.pt']:
                    rel_path = file_path.relative_to(COMFYUI_UNET_DIR)
                    unet_models.append(str(rel_path))
            logger.info(f"âœ“ æ‰¾åˆ° {len(unet_models)} å€‹ UNET æ¨¡å‹")
        else:
            logger.warning(f"UNET ç›®éŒ„ä¸å­˜åœ¨: {COMFYUI_UNET_DIR}")
    except Exception as e:
        logger.error(f"æƒæ UNET å¤±æ•—: {e}")
    
    # å¦‚æœæ²’æœ‰æ‰¾åˆ°ä»»ä½•æ¨¡å‹ï¼Œè¿”å›é è¨­åˆ—è¡¨
    if not models and not unet_models:
        logger.warning("æœªæ‰¾åˆ°ä»»ä½•æ¨¡å‹ï¼Œè¿”å›é è¨­åˆ—è¡¨")
        models = ["default_model.safetensors"]
        unet_models = ["z-image/z-image-turbo-fp8-e4m3fn.safetensors"]
    
    return jsonify({
        'models': sorted(models),
        'unet_models': sorted(unet_models)
    }), 200


# ============================================
# Static File Serving (for generated images/videos)
# ============================================
@app.route('/outputs/<path:filename>', methods=['GET'])
def serve_output(filename):
    """
    GET /outputs/<filename>
    Serve generated images/videos from storage/outputs directory
    æ”¯æ´ .png, .jpg, .mp4 ç­‰æ ¼å¼
    é˜²æ­¢è·¯å¾‘ç©¿è¶Šæ”»æ“Š
    """
    import os
    import mimetypes
    from flask import send_from_directory, abort, Response
    
    # Get the absolute path to storage/outputs
    current_dir = os.path.dirname(os.path.abspath(__file__))
    outputs_dir = os.path.join(current_dir, '..', '..', 'storage', 'outputs')
    outputs_dir = os.path.abspath(outputs_dir)
    
    # ===== å®‰å…¨æ€§ï¼šé˜²æ­¢è·¯å¾‘ç©¿è¶Šæ”»æ“Š =====
    # ç¢ºä¿è«‹æ±‚çš„æª”æ¡ˆè·¯å¾‘åš´æ ¼ä½æ–¼ outputs_dir å…§
    file_path = os.path.abspath(os.path.join(outputs_dir, filename))
    if not file_path.startswith(outputs_dir):
        logger.warning(f"âš ï¸ è·¯å¾‘ç©¿è¶Šæ”»æ“Šå˜—è©¦: {filename}")
        return abort(403)  # Forbidden
    
    logger.info(f"ğŸ“ Serving file: {filename} from {outputs_dir}")
    
    # Check if file exists
    if not os.path.exists(file_path):
        logger.warning(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return abort(404)
    
    # ç¢ºä¿æ­£ç¢ºçš„ MIME Type (ç‰¹åˆ¥æ˜¯å½±ç‰‡æª”æ¡ˆ)
    mimetype, _ = mimetypes.guess_type(file_path)
    if mimetype is None:
        # æ ¹æ“šå‰¯æª”åæ‰‹å‹•è¨­å®š
        ext = os.path.splitext(filename)[1].lower()
        mime_map = {
            '.mp4': 'video/mp4',
            '.webm': 'video/webm',
            '.avi': 'video/x-msvideo',
            '.mov': 'video/quicktime',
            '.png': 'image/png',
            '.jpg': 'image/jpeg',
            '.jpeg': 'image/jpeg',
            '.gif': 'image/gif',
            '.webp': 'image/webp',
        }
        mimetype = mime_map.get(ext, 'application/octet-stream')
    
    logger.info(f"ğŸ“¹ MIME Type: {mimetype}")
    return send_from_directory(outputs_dir, filename, mimetype=mimetype)


# ============================================
# Application Entry Point
# ============================================

# Serve frontend static files
@app.route('/')
def serve_index():
    """æä¾›å‰ç«¯ index.html"""
    try:
        frontend_dir = os.path.join(os.path.dirname(__file__), '..', '..', 'frontend')
        frontend_dir = os.path.abspath(frontend_dir)
        index_path = os.path.join(frontend_dir, 'index.html')
        
        logger.info(f"Serving index.html from: {frontend_dir}")
        logger.info(f"index.html exists: {os.path.exists(index_path)}")
        
        if not os.path.exists(index_path):
            logger.error(f"index.html not found at {index_path}")
            return jsonify({"error": "Frontend not found"}), 404
            
        return send_from_directory(frontend_dir, 'index.html')
    except Exception as e:
        logger.error(f"Error serving index: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/<path:path>')
def serve_static(path):
    """æä¾›å‰ç«¯éœæ…‹æ–‡ä»¶ï¼ˆCSS, JS, åœ–ç‰‡ç­‰ï¼‰"""
    # é€™äº›è·¯å¾‘å·²ç¶“æœ‰å°ˆé–€çš„è·¯ç”±è™•ç†ï¼Œè·³é
    # æ³¨æ„: ä¸è¦ raise NotFound()ï¼Œè€Œæ˜¯ç›´æ¥ pass through
    if path.startswith('api/') or path.startswith('health') or path.startswith('outputs/'):
        # è¿”å› 404ï¼Œè®“å…¶ä»–è·¯ç”±æ¥ç®¡
        return jsonify({"error": "Not found"}), 404
    
    try:
        frontend_dir = os.path.join(os.path.dirname(__file__), '..', '..', 'frontend')
        frontend_dir = os.path.abspath(frontend_dir)
        file_path = os.path.join(frontend_dir, path)
        
        logger.info(f"Serving static file: {path} from {frontend_dir}")
        logger.info(f"File exists: {os.path.exists(file_path)}")
        
        # å˜—è©¦è¿”å›éœæ…‹æ–‡ä»¶
        if os.path.exists(file_path) and os.path.isfile(file_path):
            return send_from_directory(frontend_dir, path)
        else:
            # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¿”å› index.htmlï¼ˆæ”¯æŒ SPA è·¯ç”±ï¼‰
            logger.warning(f"File not found: {path}, serving index.html instead")
            return send_from_directory(frontend_dir, 'index.html')
            
    except Exception as e:
        logger.error(f"Error serving static file {path}: {e}")
        return jsonify({"error": str(e)}), 500

# ==========================================
# å•Ÿå‹• Flask æ‡‰ç”¨
# ==========================================
if __name__ == '__main__':
    import sys
    logger.info("ğŸš€ Backend API å¯åŠ¨ä¸­...")
    logger.info("ğŸ“ åŒæ™‚æä¾›å‰ç«¯éœæ…‹æ–‡ä»¶æœå‹™")
    
    # Windows ä¸‹ Flask reloader æœ‰æ™‚æœƒå°è‡´é€²ç¨‹ç«‹å³é€€å‡º
    # ä½¿ç”¨ threaded=True ç¢ºä¿æœå‹™ç©©å®šé‹è¡Œ
    # use_reloader=False é¿å… Windows ä¸Šçš„ reloader å•é¡Œ
    is_windows = sys.platform.startswith('win')
    
    if is_windows:
        # Windows: ç¦ç”¨ reloader é¿å…é€²ç¨‹é€€å‡ºå•é¡Œ
        app.run(
            host='0.0.0.0', 
            port=5000, 
            debug=True, 
            use_reloader=False,
            threaded=True
        )
    else:
        # Linux/Mac: æ­£å¸¸ä½¿ç”¨ reloader
        app.run(host='0.0.0.0', port=5000, debug=True)