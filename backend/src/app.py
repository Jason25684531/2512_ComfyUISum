"""
Backend API for Studio Core
æä¾›ä»»åŠ¡æäº¤å’ŒçŠ¶æ€æŸ¥è¯¢çš„æ¥å£
"""
import os
import json
import uuid
import logging
from datetime import datetime
from flask import Flask, request, jsonify
from flask_cors import CORS
from redis import Redis, RedisError

# ============================================
# Configuration & Logging Setup
# ============================================
app = Flask(__name__)

# è¨­å®š CORS - å…è¨±æ‰€æœ‰ä¾†æºçš„è·¨åŸŸè«‹æ±‚
CORS(app, 
     origins=["*"],
     allow_headers=["Content-Type", "Authorization", "X-Requested-With"],
     methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
     supports_credentials=False)

# æ‰‹å‹•è™•ç† OPTIONS é æª¢è«‹æ±‚
@app.before_request
def handle_preflight():
    if request.method == "OPTIONS":
        response = app.make_default_options_response()
        response.headers["Access-Control-Allow-Origin"] = "*"
        response.headers["Access-Control-Allow-Methods"] = "GET, POST, PUT, DELETE, OPTIONS"
        response.headers["Access-Control-Allow-Headers"] = "Content-Type, Authorization, X-Requested-With"
        return response

@app.after_request
def after_request(response):
    response.headers["Access-Control-Allow-Origin"] = "*"
    response.headers["Access-Control-Allow-Methods"] = "GET, POST, PUT, DELETE, OPTIONS"
    response.headers["Access-Control-Allow-Headers"] = "Content-Type, Authorization, X-Requested-With"
    return response

# é…ç½®æ—¥å¿—è®°å½•å™¨
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('backend.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# å¾ config è¼‰å…¥é…ç½®
from config import (
    REDIS_HOST, REDIS_PORT, REDIS_PASSWORD, JOB_QUEUE,
    STORAGE_OUTPUT_DIR
)
REDIS_QUEUE_NAME = JOB_QUEUE

# ============================================
# Database Connection Setup
# ============================================
from database import Database

# è¼‰å…¥è³‡æ–™åº«é…ç½®
DB_HOST = os.getenv("DB_HOST", "localhost")
DB_PORT = int(os.getenv("DB_PORT", 3306))
DB_USER = os.getenv("DB_USER", "studio_user")
DB_PASSWORD = os.getenv("DB_PASSWORD", "studio_password")
DB_NAME = os.getenv("DB_NAME", "studio_db")

# åˆå§‹åŒ–è³‡æ–™åº«é€£æ¥
db_client = None
try:
    db_client = Database(
        host=DB_HOST,
        port=DB_PORT,
        user=DB_USER,
        password=DB_PASSWORD,
        database=DB_NAME
    )
    logger.info(f"âœ“ è³‡æ–™åº«é€£æ¥æˆåŠŸ: {DB_HOST}:{DB_PORT}/{DB_NAME}")
except Exception as e:
    logger.warning(f"âš ï¸ è³‡æ–™åº«é€£æ¥å¤±æ•— (åŠŸèƒ½é™ç´š): {e}")

# ============================================
# Redis Connection Setup
# ============================================
try:
    redis_client = Redis(
        host=REDIS_HOST, 
        port=REDIS_PORT, 
        password=REDIS_PASSWORD,
        decode_responses=True
    )
    redis_client.ping()
    logger.info(f"âœ“ Redis è¿æ¥æˆåŠŸ: {REDIS_HOST}:{REDIS_PORT}")
except RedisError as e:
    logger.error(f"âœ— Redis è¿æ¥å¤±è´¥: {e}")
    redis_client = None

# ============================================
# API Endpoints
# ============================================

@app.route('/api/generate', methods=['POST', 'OPTIONS'])
def generate():
    """
    POST /api/generate
    æ¥æ”¶ç”Ÿæˆè¯·æ±‚å¹¶å°†ä»»åŠ¡æ¨é€åˆ° Redis é˜Ÿåˆ—
    
    Request Body:
    {
        "prompt": "a cyberpunk cat",
        "seed": 12345,
        "workflow": "sdxl"
    }
    
    Response:
    {
        "job_id": "uuid...",
        "status": "queued"
    }
    """
    try:
        # 1. éªŒè¯è¯·æ±‚æ•°æ®
        data = request.get_json()
        if not data:
            logger.warning("è¯·æ±‚ç¼ºå°‘ JSON æ•°æ®")
            return jsonify({'error': 'Missing JSON data'}), 400
        
        prompt = data.get('prompt', '').strip()
        workflow = data.get('workflow', 'text_to_image')
        
        # åªæœ‰ text_to_image éœ€è¦ prompt
        if workflow == 'text_to_image' and not prompt:
            logger.warning("text_to_image çš„ prompt å‚æ•°ä¸ºç©º")
            return jsonify({'error': 'prompt is required for text_to_image'}), 400
        
        # 2. ç”Ÿæˆå”¯ä¸€çš„ job_id
        job_id = str(uuid.uuid4())
        
        # 3. æ„é€ ä»»åŠ¡æ•°æ® (åŒ…å«æ‰€æœ‰å‰ç«¯å‚³ä¾†çš„åƒæ•¸)
        job_data = {
            'job_id': job_id,
            'prompt': prompt,
            'seed': data.get('seed', -1),  # -1 è¡¨ç¤ºéšæœº
            'workflow': data.get('workflow', 'text_to_image'),
            'model': data.get('model', 'turbo_fp8'),
            'aspect_ratio': data.get('aspect_ratio', '1:1'),
            'batch_size': data.get('batch_size', 1),
            'images': data.get('images', {}),  # Base64 åœ–ç‰‡å­—å…¸
            'created_at': datetime.now().isoformat()
        }
        
        # 4. æ¨é€åˆ° Redis é˜Ÿåˆ—
        if redis_client is None:
            logger.error("Redis å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return jsonify({'error': 'Redis service unavailable'}), 503
        
        redis_client.rpush(REDIS_QUEUE_NAME, json.dumps(job_data))
        logger.info(f"âœ“ ä»»åŠ¡å·²æ¨é€åˆ°é˜Ÿåˆ—: job_id={job_id}, prompt='{prompt}'")
        
        # 5. åˆå§‹åŒ–çŠ¶æ€ Hash
        status_key = f"job:status:{job_id}"
        redis_client.hset(status_key, mapping={
            'job_id': job_id,
            'status': 'queued',
            'progress': 0,
            'image_url': '',
            'error': '',
            'updated_at': datetime.now().isoformat()
        })
        redis_client.expire(status_key, 86400)  # 24å°æ—¶è¿‡æœŸ
        
        # 6. å¯«å…¥è³‡æ–™åº« (å¦‚æœè³‡æ–™åº«å¯ç”¨)
        if db_client:
            db_client.insert_job(
                job_id=job_id,
                prompt=prompt,
                workflow=workflow,
                model=job_data.get('model', 'turbo_fp8'),
                aspect_ratio=job_data.get('aspect_ratio', '1:1'),
                batch_size=job_data.get('batch_size', 1),
                seed=job_data.get('seed', -1),
                status='queued'
            )
        
        # 7. è¿”å›æˆåŠŸå“åº”
        return jsonify({
            'job_id': job_id,
            'status': 'queued'
        }), 202
    
    except Exception as e:
        logger.error(f"âœ— generate æ¥å£å¼‚å¸¸: {e}", exc_info=True)
        return jsonify({'error': 'Internal server error'}), 500


@app.route('/api/status/<job_id>', methods=['GET'])
def status(job_id):
    """
    GET /api/status/<job_id>
    æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
    
    Response:
    {
        "job_id": "...",
        "status": "processing",
        "progress": 50,
        "image_url": null,
        "error": ""
    }
    """
    try:
        if redis_client is None:
            logger.error("Redis å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return jsonify({'error': 'Redis service unavailable'}), 503
        
        # ä» Redis è¯»å–çŠ¶æ€
        status_key = f"job:status:{job_id}"
        job_status = redis_client.hgetall(status_key)
        
        if not job_status:
            logger.warning(f"ä»»åŠ¡ä¸å­˜åœ¨: job_id={job_id}")
            return jsonify({'error': 'Job not found'}), 404
        
        # å¦‚æœä»»å‹™å·²å®Œæˆä¸”è³‡æ–™åº«å¯ç”¨ï¼ŒåŒæ­¥ç‹€æ…‹åˆ°è³‡æ–™åº«
        current_status = job_status.get('status', 'unknown')
        if db_client and current_status in ['finished', 'failed', 'cancelled']:
            output_path = job_status.get('image_url', '')
            db_client.update_job_status(job_id, current_status, output_path)
        
        # è¿”å›çŠ¶æ€ä¿¡æ¯
        return jsonify({
            'job_id': job_status.get('job_id', job_id),
            'status': job_status.get('status', 'unknown'),
            'progress': int(job_status.get('progress', 0)),
            'image_url': job_status.get('image_url', ''),
            'error': job_status.get('error', '')
        }), 200
    
    except Exception as e:
        logger.error(f"âœ— status æ¥å£å¼‚å¸¸: {e}", exc_info=True)
        return jsonify({'error': 'Internal server error'}), 500


@app.route('/api/cancel/<job_id>', methods=['POST'])
def cancel_job(job_id):
    """
    POST /api/cancel/<job_id>
    å–æ¶ˆæ­£åœ¨åŸ·è¡Œçš„ä»»å‹™
    
    Response:
    {
        "success": true,
        "message": "Task cancelled"
    }
    """
    try:
        if redis_client is None:
            logger.error("Redis å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return jsonify({'error': 'Redis service unavailable'}), 503
        
        # æª¢æŸ¥ä»»å‹™æ˜¯å¦å­˜åœ¨
        status_key = f"job:status:{job_id}"
        job_status = redis_client.hgetall(status_key)
        
        if not job_status:
            logger.warning(f"ä»»å‹™ä¸å­˜åœ¨: job_id={job_id}")
            return jsonify({'error': 'Job not found'}), 404
        
        current_status = job_status.get('status', 'unknown')
        
        # å¦‚æœä»»å‹™å·²ç¶“å®Œæˆæˆ–å¤±æ•—ï¼Œç„¡æ³•å–æ¶ˆ
        if current_status in ['finished', 'failed', 'cancelled']:
            return jsonify({
                'success': False,
                'message': f'Cannot cancel job with status: {current_status}'
            }), 400
        
        # å°‡ç‹€æ…‹è¨­ç½®ç‚º cancelled
        redis_client.hset(status_key, 'status', 'cancelled')
        redis_client.hset(status_key, 'error', 'Task cancelled by user')
        
        logger.info(f"âœ“ ä»»å‹™å·²æ¨™è¨˜ç‚ºå–æ¶ˆ: job_id={job_id}")
        
        return jsonify({
            'success': True,
            'message': 'Task cancelled'
        }), 200
    
    except Exception as e:
        logger.error(f"âœ— cancel æ¥å£å¼‚å¸¸: {e}", exc_info=True)
        return jsonify({'error': 'Internal server error'}), 500


@app.route('/api/history', methods=['GET'])
def get_history():
    """
    GET /api/history?limit=50&offset=0
    ç²å–æ­·å²è¨˜éŒ„åˆ—è¡¨
    
    Query Parameters:
        limit: è¿”å›æ•¸é‡ (é è¨­ 50)
        offset: åç§»é‡ (é è¨­ 0)
    
    Response:
    {
        "total": 120,
        "limit": 50,
        "offset": 0,
        "jobs": [
            {
                "id": "uuid",
                "prompt": "...",
                "workflow": "text_to_image",
                "model": "turbo_fp8",
                "status": "finished",
                "output_path": "/outputs/xxx.png,/outputs/yyy.png",
                "created_at": "2024-12-31T10:00:00"
            }
        ]
    }
    """
    try:
        if db_client is None:
            logger.error("è³‡æ–™åº«æœªåˆå§‹åŒ–")
            return jsonify({'error': 'Database service unavailable'}), 503
        
        # è§£ææŸ¥è©¢åƒæ•¸
        limit = int(request.args.get('limit', 50))
        offset = int(request.args.get('offset', 0))
        
        # é™åˆ¶å–®æ¬¡æŸ¥è©¢æ•¸é‡
        limit = min(limit, 100)
        
        # å¾è³‡æ–™åº«ç²å–æ­·å²è¨˜éŒ„
        jobs = db_client.get_history(limit=limit, offset=offset)
        
        logger.info(f"âœ“ æŸ¥è©¢æ­·å²è¨˜éŒ„: {len(jobs)} ç­† (limit={limit}, offset={offset})")
        
        return jsonify({
            'total': len(jobs),  # ç°¡åŒ–ç‰ˆæœ¬ï¼Œå¯¦éš›å¯æŸ¥è©¢ç¸½æ•¸
            'limit': limit,
            'offset': offset,
            'jobs': jobs
        }), 200
    
    except Exception as e:
        logger.error(f"âœ— history æ¥å£å¼‚å¸¸: {e}", exc_info=True)
        return jsonify({'error': 'Internal server error'}), 500


@app.route('/health', methods=['GET'])
def health():
    """å¥åº·æ£€æŸ¥æ¥å£ - æª¢æŸ¥ Redis å’Œ MySQL ç‹€æ…‹"""
    redis_status = 'healthy' if redis_client and redis_client.ping() else 'unavailable'
    
    mysql_status = 'unavailable'
    if db_client:
        mysql_status = 'healthy' if db_client.check_connection() else 'error'
    
    overall_status = 'ok' if redis_status == 'healthy' else 'degraded'
    
    return jsonify({
        'status': overall_status,
        'redis': redis_status,
        'mysql': mysql_status
    }), 200


@app.route('/api/models', methods=['GET'])
def get_models():
    """
    GET /api/models
    æƒæ ComfyUI æ¨¡å‹ç›®éŒ„ï¼Œå›å‚³å¯ç”¨æ¨¡å‹åˆ—è¡¨
    
    Response:
    {
        "models": ["model1.safetensors", "model2.ckpt"],
        "unet_models": ["unet1.safetensors"]
    }
    """
    from config import COMFYUI_CHECKPOINTS_DIR, COMFYUI_UNET_DIR
    
    models = []
    unet_models = []
    
    # æƒæ Checkpoints ç›®éŒ„
    try:
        if COMFYUI_CHECKPOINTS_DIR.exists():
            for file_path in COMFYUI_CHECKPOINTS_DIR.rglob("*"):
                if file_path.is_file() and file_path.suffix.lower() in ['.safetensors', '.ckpt']:
                    # ä½¿ç”¨ç›¸å°è·¯å¾‘ï¼ˆç›¸å°æ–¼ checkpoints ç›®éŒ„ï¼‰
                    rel_path = file_path.relative_to(COMFYUI_CHECKPOINTS_DIR)
                    models.append(str(rel_path))
            logger.info(f"âœ“ æ‰¾åˆ° {len(models)} å€‹ Checkpoint æ¨¡å‹")
        else:
            logger.warning(f"Checkpoints ç›®éŒ„ä¸å­˜åœ¨: {COMFYUI_CHECKPOINTS_DIR}")
    except Exception as e:
        logger.error(f"æƒæ Checkpoints å¤±æ•—: {e}")
    
    # æƒæ UNET ç›®éŒ„
    try:
        if COMFYUI_UNET_DIR.exists():
            for file_path in COMFYUI_UNET_DIR.rglob("*"):
                if file_path.is_file() and file_path.suffix.lower() in ['.safetensors', '.ckpt', '.pt']:
                    rel_path = file_path.relative_to(COMFYUI_UNET_DIR)
                    unet_models.append(str(rel_path))
            logger.info(f"âœ“ æ‰¾åˆ° {len(unet_models)} å€‹ UNET æ¨¡å‹")
        else:
            logger.warning(f"UNET ç›®éŒ„ä¸å­˜åœ¨: {COMFYUI_UNET_DIR}")
    except Exception as e:
        logger.error(f"æƒæ UNET å¤±æ•—: {e}")
    
    # å¦‚æœæ²’æœ‰æ‰¾åˆ°ä»»ä½•æ¨¡å‹ï¼Œè¿”å›é è¨­åˆ—è¡¨
    if not models and not unet_models:
        logger.warning("æœªæ‰¾åˆ°ä»»ä½•æ¨¡å‹ï¼Œè¿”å›é è¨­åˆ—è¡¨")
        models = ["default_model.safetensors"]
        unet_models = ["z-image/z-image-turbo-fp8-e4m3fn.safetensors"]
    
    return jsonify({
        'models': sorted(models),
        'unet_models': sorted(unet_models)
    }), 200


# ============================================
# Static File Serving (for generated images)
# ============================================
@app.route('/outputs/<path:filename>', methods=['GET'])
def serve_output(filename):
    """
    GET /outputs/<filename>
    Serve generated images from storage/outputs directory
    """
    import os
    from flask import send_from_directory, abort
    
    # Get the absolute path to storage/outputs
    current_dir = os.path.dirname(os.path.abspath(__file__))
    outputs_dir = os.path.join(current_dir, '..', '..', 'storage', 'outputs')
    outputs_dir = os.path.abspath(outputs_dir)
    
    logger.info(f"ğŸ“ Serving file: {filename} from {outputs_dir}")
    
    # Check if file exists
    file_path = os.path.join(outputs_dir, filename)
    if not os.path.exists(file_path):
        logger.warning(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return abort(404)
    
    return send_from_directory(outputs_dir, filename)


# ============================================
# Application Entry Point
# ============================================
if __name__ == '__main__':
    logger.info("ğŸš€ Backend API å¯åŠ¨ä¸­...")
    app.run(host='0.0.0.0', port=5000, debug=True)