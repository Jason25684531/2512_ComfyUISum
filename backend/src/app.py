"""
Backend API for Studio Core
æä¾›ä»»åŠ¡æäº¤å’ŒçŠ¶æ€æŸ¥è¯¢çš„æ¥å£
"""
import os
import sys
import json
import uuid
import logging
import threading
import time
from logging.handlers import RotatingFileHandler
from datetime import datetime
from pathlib import Path
from flask import Flask, request, jsonify, send_from_directory, g
from flask_cors import CORS
from flask_limiter import Limiter
from flask_limiter.util import get_remote_address
from redis import Redis, RedisError
from werkzeug.utils import secure_filename
from rich.logging import RichHandler
from rich.panel import Panel
from rich.console import Console

# ============================================
# æ·»åŠ  shared æ¨¡çµ„è·¯å¾‘ä¸¦è¼‰å…¥ .env
# ============================================
sys.path.insert(0, str(Path(__file__).parent.parent.parent))
from shared.utils import load_env
load_env()

# ============================================
# Configuration & Logging Setup
# ============================================
app = Flask(__name__)
CORS(app)

# ============================================
# è‡ªè¨‚æ—¥èªŒéæ¿¾å™¨
# ============================================

class UserIdFilter(logging.Filter):
    """æ—¥èªŒéæ¿¾å™¨ï¼Œå°‡ g.user_id æ³¨å…¥åˆ°æ—¥èªŒè¨˜éŒ„ä¸­"""
    def filter(self, record):
        try:
            # å¾ Flask ä¸Šä¸‹æ–‡ä¸­ç²å– user_idï¼Œå¦‚æœä¸å­˜åœ¨å‰‡ä½¿ç”¨ 'INIT'
            user_id = getattr(g, 'user_id', 'INIT')
        except (RuntimeError, AttributeError):
            # åœ¨æ‡‰ç”¨ä¸Šä¸‹æ–‡å¤–æˆ–æ²’æœ‰æ´»èºè«‹æ±‚æ™‚ï¼Œä½¿ç”¨é è¨­å€¼
            user_id = 'INIT'
        
        record.user_id = user_id
        return True

# ============================================

# åˆå§‹åŒ– Rate Limiter (ä½¿ç”¨ Redis ä½œç‚ºå„²å­˜å¾Œç«¯)
limiter = Limiter(
    app=app,
    key_func=get_remote_address,
    storage_uri=None,  # å°‡åœ¨å¾ŒçºŒè¨­ç½®
    # default_limits=["100 per hour"],
    default_limits=["10000 per hour"],  # <-- æ”¹æˆé€™æ¨£ï¼Œæˆ–è€…ç›´æ¥æ‹¿æ‰é€™è¡Œ
    storage_options={"socket_connect_timeout": 30},
    strategy="fixed-window"
)

# è¨­å®š CORS - å…è¨±æ‰€æœ‰ä¾†æºçš„è·¨åŸŸè«‹æ±‚
CORS(app, 
     origins=["*"],
     allow_headers=["Content-Type", "Authorization", "X-Requested-With"],
     methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
     supports_credentials=False)

# æ‰‹å‹•è™•ç† OPTIONS é æª¢è«‹æ±‚
@app.before_request
def before_request_handler():
    """
    åœ¨æ¯å€‹è«‹æ±‚å‰è™•ç†ï¼š
    1. æå–å®¢æˆ¶ç«¯ IP åœ°å€
    2. å¾è³‡æ–™åº«ç²å–æˆ–å»ºç«‹ç”¨æˆ¶ ID
    3. å­˜å„²åˆ° Flask g å°è±¡ï¼Œä¾›æ—¥èªŒä½¿ç”¨
    """
    # ç²å–å®¢æˆ¶ç«¯ IP åœ°å€ï¼ˆè€ƒæ…®ä»£ç†ï¼‰
    ip_address = request.headers.get('X-Forwarded-For')
    if ip_address:
        # ä»£ç†æƒ…æ³ä¸‹ï¼Œå–ç¬¬ä¸€å€‹ IP
        ip_address = ip_address.split(',')[0].strip()
    else:
        ip_address = request.remote_addr or 'unknown'
    
    # å¾è³‡æ–™åº«ç²å–æˆ–å»ºç«‹ç”¨æˆ¶ ID
    if db_client:
        user_id = db_client.get_or_create_user_id(ip_address)
        if user_id > 0:
            g.user_id = f"User#{user_id:03d}"
        else:
            g.user_id = "User#ERR"
    else:
        g.user_id = "User#N/A"
    
    # è¨˜éŒ„è«‹æ±‚é–‹å§‹
    logger.debug(f"ğŸ“¨ {request.method} {request.path} - IP: {ip_address}")

# æ‰‹å‹•è™•ç† OPTIONS é æª¢è«‹æ±‚
@app.before_request
def handle_preflight():
    if request.method == "OPTIONS":
        response = app.make_default_options_response()
        response.headers["Access-Control-Allow-Origin"] = "*"
        response.headers["Access-Control-Allow-Methods"] = "GET, POST, PUT, DELETE, OPTIONS"
        response.headers["Access-Control-Allow-Headers"] = "Content-Type, Authorization, X-Requested-With"
        return response

@app.after_request
def after_request(response):
    response.headers["Access-Control-Allow-Origin"] = "*"
    response.headers["Access-Control-Allow-Methods"] = "GET, POST, PUT, DELETE, OPTIONS"
    response.headers["Access-Control-Allow-Headers"] = "Content-Type, Authorization, X-Requested-With"
    
    # è¨˜éŒ„è«‹æ±‚å®Œæˆ
    logger.info(f"âœ“ {request.method} {request.path} - {response.status_code}")
    
    return response

# é…ç½®æ—¥å¿—è®°å½•å™¨
# æ–‡ä»¶æ—¥å¿—æ ¼å¼ï¼ˆè©³ç´°ï¼‰
file_log_formatter = logging.Formatter('[%(user_id)s] %(asctime)s - %(name)s - %(levelname)s - %(message)s')

# ç¢ºä¿ logs ç›®éŒ„å­˜åœ¨
log_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', '..', 'logs')
os.makedirs(log_dir, exist_ok=True)
log_file = os.path.join(log_dir, 'backend.log')

# é…ç½® RotatingFileHandler (5MB, ä¿ç•™ 3 ä»½) - ç”¨æ–¼æ–‡ä»¶æŒä¹…åŒ–
file_handler = RotatingFileHandler(
    log_file,
    maxBytes=5*1024*1024,  # 5MB
    backupCount=3,
    encoding='utf-8'
)
file_handler.setFormatter(file_log_formatter)
file_handler.setLevel(logging.INFO)
file_handler.addFilter(UserIdFilter())

# é…ç½® RichHandler (ç”¨æ–¼çµ‚ç«¯é¡¯ç¤ºï¼Œè‡ªå‹•ç€è‰²å’Œæ ¼å¼åŒ–)
console_handler = RichHandler(
    rich_tracebacks=True,  # å•Ÿç”¨è©³ç´°çš„å †æ£§è·Ÿè¹¤
    markup=True,           # æ”¯æŒ Rich æ¨™è¨˜
    show_time=True,        # é¡¯ç¤ºæ™‚é–“
    show_level=True,       # é¡¯ç¤ºæ—¥èªŒç´šåˆ¥
    show_path=False        # ä¸é¡¯ç¤ºæ–‡ä»¶è·¯å¾‘ï¼ˆçµ‚ç«¯å¯¬åº¦æœ‰é™ï¼‰
)
console_handler.setLevel(logging.INFO)
console_handler.addFilter(UserIdFilter())

# é…ç½® root logger
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)
logger.addHandler(file_handler)
logger.addHandler(console_handler)

# åŒæ™‚é…ç½® Flask app logger
app.logger.setLevel(logging.DEBUG)
app.logger.addHandler(file_handler)
app.logger.addHandler(console_handler)

# å…¨å±€ console å¯¦ä¾‹ï¼ˆä¾›åº•éƒ¨ç‹€æ…‹åˆ—ä½¿ç”¨ï¼‰
console = Console()

# å¾ config è¼‰å…¥é…ç½®
from config import (
    REDIS_HOST, REDIS_PORT, REDIS_PASSWORD, JOB_QUEUE,
    STORAGE_OUTPUT_DIR
)
REDIS_QUEUE_NAME = JOB_QUEUE

# ============================================
# Database Connection Setup
# ============================================
from database import Database

# è¼‰å…¥è³‡æ–™åº«é…ç½®
DB_HOST = os.getenv("DB_HOST", "localhost")
DB_PORT = int(os.getenv("DB_PORT", 3306))
DB_USER = os.getenv("DB_USER", "studio_user")
DB_PASSWORD = os.getenv("DB_PASSWORD", "studio_password")
DB_NAME = os.getenv("DB_NAME", "studio_db")

# åˆå§‹åŒ–è³‡æ–™åº«é€£æ¥
db_client = None
try:
    db_client = Database(
        host=DB_HOST,
        port=DB_PORT,
        user=DB_USER,
        password=DB_PASSWORD,
        database=DB_NAME
    )
    logger.info(f"âœ“ è³‡æ–™åº«é€£æ¥æˆåŠŸ: {DB_HOST}:{DB_PORT}/{DB_NAME}")
except Exception as e:
    logger.warning(f"âš ï¸ è³‡æ–™åº«é€£æ¥å¤±æ•— (åŠŸèƒ½é™ç´š): {e}")

# ============================================
# Redis Connection Setup
# ============================================
try:
    redis_client = Redis(
        host=REDIS_HOST, 
        port=REDIS_PORT, 
        password=REDIS_PASSWORD,
        decode_responses=True
    )
    redis_client.ping()
    logger.info(f"âœ“ Redis è¿æ¥æˆåŠŸ: {REDIS_HOST}:{REDIS_PORT}")
    
    # é…ç½® Limiter ä½¿ç”¨ Redis
    limiter.storage_uri = f"redis://:{REDIS_PASSWORD}@{REDIS_HOST}:{REDIS_PORT}/1"
    
except RedisError as e:
    logger.error(f"âœ— Redis è¿æ¥å¤±è´¥: {e}")
    redis_client = None

# ============================================
# éŸ³è¨Šä¸Šå‚³è¨­å®š
# ============================================
ALLOWED_AUDIO_EXTENSIONS = {'.wav', '.mp3'}
UPLOAD_FOLDER = Path(__file__).parent.parent.parent / 'storage' / 'inputs'
UPLOAD_FOLDER.mkdir(parents=True, exist_ok=True)


# ============================================
# API Endpoints
# ============================================

@app.route('/api/upload', methods=['POST'])
@limiter.limit("30 per minute")
def upload_audio():
    """
    POST /api/upload
    ä¸Šå‚³éŸ³è¨Šæª”æ¡ˆ (æ”¯æ´ .wav, .mp3)
    
    Request: multipart/form-data, Key: 'file'
    
    Response:
    {
        "filename": "audio_550e8400-e29b.wav",
        "original_name": "æ—å¿—ç².wav"
    }
    """
    try:
        # 1. é©—è­‰æª”æ¡ˆæ˜¯å¦å­˜åœ¨
        if 'file' not in request.files:
            logger.warning("ä¸Šå‚³è«‹æ±‚ç¼ºå°‘ 'file' æ¬„ä½")
            return jsonify({'error': 'No file provided'}), 400
        
        file = request.files['file']
        
        if file.filename == '':
            logger.warning("ä¸Šå‚³çš„æª”æ¡ˆåç¨±ç‚ºç©º")
            return jsonify({'error': 'No file selected'}), 400
        
        # 2. é©—è­‰æª”æ¡ˆé¡å‹
        original_filename = secure_filename(file.filename)
        file_ext = os.path.splitext(original_filename)[1].lower()
        
        if file_ext not in ALLOWED_AUDIO_EXTENSIONS:
            logger.warning(f"ä¸æ”¯æ´çš„éŸ³è¨Šæ ¼å¼: {file_ext}")
            return jsonify({
                'error': f'Unsupported file type. Allowed: {", ".join(ALLOWED_AUDIO_EXTENSIONS)}'
            }), 400
        
        # 3. ç”Ÿæˆå”¯ä¸€æª”å (ä¿ç•™åŸå‰¯æª”å)
        unique_id = str(uuid.uuid4())[:12]
        new_filename = f"audio_{unique_id}{file_ext}"
        
        # 4. ç¢ºä¿å®‰å…¨çš„æª”å
        safe_filename = secure_filename(new_filename)
        
        # 5. å„²å­˜æª”æ¡ˆ
        file_path = UPLOAD_FOLDER / safe_filename
        
        try:
            file.save(str(file_path))
            logger.info(f"âœ… éŸ³è¨Šä¸Šå‚³æˆåŠŸ: {safe_filename} (åŸå§‹: {original_filename})")
        except PermissionError as e:
            logger.error(f"âŒ å„²å­˜æª”æ¡ˆæ¬Šé™ä¸è¶³: {e}")
            return jsonify({'error': 'Permission denied when saving file'}), 500
        except FileNotFoundError as e:
            logger.error(f"âŒ å„²å­˜è·¯å¾‘ä¸å­˜åœ¨: {e}")
            return jsonify({'error': 'Upload directory not found'}), 500
        
        # 6. å›å‚³çµæœ
        return jsonify({
            'filename': safe_filename,
            'original_name': file.filename  # ä½¿ç”¨åŸå§‹æª”åï¼ˆæœªç¶“ secure_filename è™•ç†ï¼‰
        }), 200
    
    except Exception as e:
        logger.error(f"âœ— upload æ¥å£ç•°å¸¸: {e}", exc_info=True)
        return jsonify({'error': 'Internal server error'}), 500


@app.route('/api/generate', methods=['POST', 'OPTIONS'])
@limiter.limit("10 per minute")
def generate():
    """
    POST /api/generate
    æ¥æ”¶ç”Ÿæˆè¯·æ±‚å¹¶å°†ä»»åŠ¡æ¨é€åˆ° Redis é˜Ÿåˆ—
    
    Request Body:
    {
        "prompt": "a cyberpunk cat",
        "seed": 12345,
        "workflow": "sdxl"
    }
    
    Response:
    {
        "job_id": "uuid...",
        "status": "queued"
    }
    """
    try:
        # 1. éªŒè¯è¯·æ±‚æ•°æ®
        data = request.get_json()
        if not data:
            logger.warning("è¯·æ±‚ç¼ºå°‘ JSON æ•°æ®")
            return jsonify({'error': 'Missing JSON data'}), 400
        
        prompt = data.get('prompt', '').strip()
        prompts = data.get('prompts', [])  # Veo3 Long Video: 5 æ®µè¦–é »çš„ prompts
        workflow = data.get('workflow', 'text_to_image')
        
        # ===== å®‰å…¨æ€§é©—è­‰ï¼šPrompt é•·åº¦é™åˆ¶ =====
        if len(prompt) > 1000:
            logger.warning(f"Prompt è¶…éé•·åº¦é™åˆ¶: {len(prompt)} > 1000")
            return jsonify({'error': 'Prompt exceeds maximum length of 1000 characters'}), 400
        
        # Veo3 Long Video: é©—è­‰ prompts åˆ—è¡¨
        if prompts:
            if not isinstance(prompts, list):
                return jsonify({'error': 'prompts must be a list'}), 400
            if len(prompts) > 10:  # æœ€å¤šæ”¯æŒ 10 å€‹ segment
                return jsonify({'error': 'Too many prompts (max 10)'}), 400
            for p in prompts:
                if len(str(p)) > 1000:
                    return jsonify({'error': 'Individual prompt exceeds maximum length'}), 400
        
        # åªæœ‰ text_to_image éœ€è¦ prompt
        if workflow == 'text_to_image' and not prompt:
            logger.warning("text_to_image çš„ prompt å‚æ•°ä¸ºç©º")
            return jsonify({'error': 'prompt is required for text_to_image'}), 400
        
        # 2. ç”Ÿæˆå”¯ä¸€çš„ job_id
        job_id = str(uuid.uuid4())
        
        # 3. æ„é€ ä»»åŠ¡æ•°æ® (åŒ…å«æ‰€æœ‰å‰ç«¯å‚³ä¾†çš„åƒæ•¸)
        job_data = {
            'job_id': job_id,
            'prompt': prompt,
            'prompts': prompts,  # Veo3 Long Video: æ–°å¢ prompts åˆ—è¡¨
            'seed': data.get('seed', -1),  # -1 è¡¨ç¤ºéšæœº
            'workflow': data.get('workflow', 'text_to_image'),
            'model': data.get('model', 'turbo_fp8'),
            'aspect_ratio': data.get('aspect_ratio', '1:1'),
            'batch_size': data.get('batch_size', 1),
            'images': data.get('images', {}),  # Base64 åœ–ç‰‡å­—å…¸
            'audio': data.get('audio', ''),  # éŸ³è¨Šæª”å (virtual_human å·¥ä½œæµä½¿ç”¨)
            'created_at': datetime.now().isoformat()
        }
        
        # 4. æ¨é€åˆ° Redis é˜Ÿåˆ—
        if redis_client is None:
            logger.error("Redis å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return jsonify({'error': 'Redis service unavailable'}), 503
        
        redis_client.rpush(REDIS_QUEUE_NAME, json.dumps(job_data))
        logger.info(f"âœ“ ä»»åŠ¡å·²æ¨é€åˆ°é˜Ÿåˆ—: job_id={job_id}, prompt='{prompt}'")
        
        # 5. åˆå§‹åŒ–çŠ¶æ€ Hash
        status_key = f"job:status:{job_id}"
        redis_client.hset(status_key, mapping={
            'job_id': job_id,
            'status': 'queued',
            'progress': 0,
            'image_url': '',
            'error': '',
            'updated_at': datetime.now().isoformat()
        })
        redis_client.expire(status_key, 86400)  # 24å°æ—¶è¿‡æœŸ
        
        # 6. å¯«å…¥è³‡æ–™åº« (å¦‚æœè³‡æ–™åº«å¯ç”¨)
        if db_client:
            db_client.insert_job(
                job_id=job_id,
                prompt=prompt,
                workflow=workflow,
                model=job_data.get('model', 'turbo_fp8'),
                aspect_ratio=job_data.get('aspect_ratio', '1:1'),
                batch_size=job_data.get('batch_size', 1),
                seed=job_data.get('seed', -1),
                status='queued',
                input_audio_path=job_data.get('audio', None)  # Phase 7: è¨˜éŒ„éŸ³è¨Šæª”å
            )
        
        # 7. è¿”å›æˆåŠŸå“åº”
        return jsonify({
            'job_id': job_id,
            'status': 'queued'
        }), 202
    
    except Exception as e:
        logger.error(f"âœ— generate æ¥å£å¼‚å¸¸: {e}", exc_info=True)
        return jsonify({'error': 'Internal server error'}), 500


@app.route('/api/status/<job_id>', methods=['GET'])
@limiter.limit("2 per second")  # æ¯ç§’ 2 æ¬¡ = æ¯åˆ†é˜ 120 æ¬¡ï¼ˆå¯¬é¬†é™åˆ¶ï¼Œé©åˆè¼ªè©¢ï¼‰
def status(job_id):
    """
    GET /api/status/<job_id>
    æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
    
    Response:
    {
        "job_id": "...",
        "status": "processing",
        "progress": 50,
        "image_url": null,
        "error": ""
    }
    """
    try:
        if redis_client is None:
            logger.error("Redis å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return jsonify({'error': 'Redis service unavailable'}), 503
        
        # ä» Redis è¯»å–çŠ¶æ€
        status_key = f"job:status:{job_id}"
        job_status = redis_client.hgetall(status_key)
        
        if not job_status:
            logger.warning(f"ä»»åŠ¡ä¸å­˜åœ¨: job_id={job_id}")
            return jsonify({'error': 'Job not found'}), 404
        
        # å¦‚æœä»»å‹™å·²å®Œæˆä¸”è³‡æ–™åº«å¯ç”¨ï¼ŒåŒæ­¥ç‹€æ…‹åˆ°è³‡æ–™åº«
        current_status = job_status.get('status', 'unknown')
        if db_client and current_status in ['finished', 'failed', 'cancelled']:
            output_path = job_status.get('image_url', '')
            db_client.update_job_status(job_id, current_status, output_path)
        
        # è¿”å›çŠ¶æ€ä¿¡æ¯
        return jsonify({
            'job_id': job_status.get('job_id', job_id),
            'status': job_status.get('status', 'unknown'),
            'progress': int(job_status.get('progress', 0)),
            'image_url': job_status.get('image_url', ''),
            'error': job_status.get('error', '')
        }), 200
    
    except Exception as e:
        logger.error(f"âœ— status æ¥å£å¼‚å¸¸: {e}", exc_info=True)
        return jsonify({'error': 'Internal server error'}), 500


@app.route('/api/cancel/<job_id>', methods=['POST'])
def cancel_job(job_id):
    """
    POST /api/cancel/<job_id>
    å–æ¶ˆæ­£åœ¨åŸ·è¡Œçš„ä»»å‹™
    
    Response:
    {
        "success": true,
        "message": "Task cancelled"
    }
    """
    try:
        if redis_client is None:
            logger.error("Redis å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return jsonify({'error': 'Redis service unavailable'}), 503
        
        # æª¢æŸ¥ä»»å‹™æ˜¯å¦å­˜åœ¨
        status_key = f"job:status:{job_id}"
        job_status = redis_client.hgetall(status_key)
        
        if not job_status:
            logger.warning(f"ä»»å‹™ä¸å­˜åœ¨: job_id={job_id}")
            return jsonify({'error': 'Job not found'}), 404
        
        current_status = job_status.get('status', 'unknown')
        
        # å¦‚æœä»»å‹™å·²ç¶“å®Œæˆæˆ–å¤±æ•—ï¼Œç„¡æ³•å–æ¶ˆ
        if current_status in ['finished', 'failed', 'cancelled']:
            return jsonify({
                'success': False,
                'message': f'Cannot cancel job with status: {current_status}'
            }), 400
        
        # å°‡ç‹€æ…‹è¨­ç½®ç‚º cancelled
        redis_client.hset(status_key, 'status', 'cancelled')
        redis_client.hset(status_key, 'error', 'Task cancelled by user')
        
        logger.info(f"âœ“ ä»»å‹™å·²æ¨™è¨˜ç‚ºå–æ¶ˆ: job_id={job_id}")
        
        return jsonify({
            'success': True,
            'message': 'Task cancelled'
        }), 200
    
    except Exception as e:
        logger.error(f"âœ— cancel æ¥å£å¼‚å¸¸: {e}", exc_info=True)
        return jsonify({'error': 'Internal server error'}), 500


@app.route('/api/history', methods=['GET'])
def get_history():
    """
    GET /api/history?limit=50&offset=0
    ç²å–æ­·å²è¨˜éŒ„åˆ—è¡¨
    
    Query Parameters:
        limit: è¿”å›æ•¸é‡ (é è¨­ 50)
        offset: åç§»é‡ (é è¨­ 0)
    
    Response:
    {
        "total": 120,
        "limit": 50,
        "offset": 0,
        "jobs": [
            {
                "id": "uuid",
                "prompt": "...",
                "workflow": "text_to_image",
                "model": "turbo_fp8",
                "status": "finished",
                "output_path": "/outputs/xxx.png,/outputs/yyy.png",
                "created_at": "2024-12-31T10:00:00"
            }
        ]
    }
    """
    try:
        if db_client is None:
            logger.error("è³‡æ–™åº«æœªåˆå§‹åŒ–")
            return jsonify({'error': 'Database service unavailable'}), 503
        
        # è§£ææŸ¥è©¢åƒæ•¸
        limit = int(request.args.get('limit', 50))
        offset = int(request.args.get('offset', 0))
        
        # é™åˆ¶å–®æ¬¡æŸ¥è©¢æ•¸é‡
        limit = min(limit, 100)
        
        logger.info(f"ğŸ“¥ æº–å‚™æŸ¥è©¢è³‡æ–™åº«: db_client={db_client is not None}, limit={limit}, offset={offset}")
        
        # å¾è³‡æ–™åº«ç²å–æ­·å²è¨˜éŒ„
        jobs = db_client.get_history(limit=limit, offset=offset)
        
        logger.info(f"ğŸ“¤ è³‡æ–™åº«è¿”å›: {len(jobs)} ç­†è¨˜éŒ„")
        
        # è™•ç† output_pathï¼šè½‰æ›ç‚ºå‰ç«¯å¯è¨ªå•çš„ URL æ ¼å¼
        for job in jobs:
            output_path = job.get('output_path')
            if output_path:
                # å¦‚æœæ˜¯é€—è™Ÿåˆ†éš”çš„å¤šå€‹è·¯å¾‘ï¼Œè™•ç†æ¯ä¸€å€‹
                paths = output_path.split(',')
                # ç§»é™¤è·¯å¾‘å‰ç¶´ï¼Œåªä¿ç•™æª”åï¼Œä¸¦è½‰æ›ç‚º URL æ ¼å¼
                formatted_paths = []
                for path in paths:
                    path = path.strip()
                    if path:
                        # æå–æª”åï¼ˆç§»é™¤å¯èƒ½çš„è·¯å¾‘å‰ç¶´ï¼‰
                        filename = path.split('/')[-1].split('\\')[-1]
                        # è½‰æ›ç‚ºå®Œæ•´ URL
                        formatted_paths.append(f"/outputs/{filename}")
                # ç”¨é€—è™Ÿé€£æ¥æ‰€æœ‰è·¯å¾‘
                job['output_path'] = ','.join(formatted_paths) if formatted_paths else ''
        
        logger.info(f"âœ“ æŸ¥è©¢æ­·å²è¨˜éŒ„: {len(jobs)} ç­† (limit={limit}, offset={offset})")
        
        return jsonify({
            'total': len(jobs),  # ç°¡åŒ–ç‰ˆæœ¬ï¼Œå¯¦éš›å¯æŸ¥è©¢ç¸½æ•¸
            'limit': limit,
            'offset': offset,
            'jobs': jobs
        }), 200
    
    except Exception as e:
        logger.error(f"âœ— history æ¥å£å¼‚å¸¸: {e}", exc_info=True)
        return jsonify({'error': 'Internal server error'}), 500


@app.route('/api/metrics', methods=['GET'])
@limiter.limit("2 per second")  # æ¯ç§’ 2 æ¬¡ = æ¯åˆ†é˜ 120 æ¬¡ï¼ˆç›£æ§å„€è¡¨æ¿å°ˆç”¨ï¼‰
def metrics():
    """
    GET /api/metrics
    ç³»çµ±ç›£æ§æŒ‡æ¨™ç«¯é»ï¼ˆPhase 6 - é«˜é »è¼ªè©¢å°ˆç”¨ï¼‰
    
    Response:
    {
        "queue_length": 5,          // Redis ä½‡åˆ—ä¸­ç­‰å¾…çš„ä»»å‹™æ•¸é‡
        "worker_status": "online",  // Worker ç‹€æ…‹ (online/offline)
        "active_jobs": 2            // ç•¶å‰æ­£åœ¨è™•ç†çš„ä»»å‹™æ•¸é‡
    }
    """
    try:
        if redis_client is None:
            logger.error("Redis å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return jsonify({'error': 'Redis service unavailable'}), 503
        
        # 1. ç²å–ä½‡åˆ—é•·åº¦
        queue_length = redis_client.llen(REDIS_QUEUE_NAME)
        
        # 2. æª¢æŸ¥ Worker å¿ƒè·³ç‹€æ…‹
        worker_heartbeat = redis_client.get('worker:heartbeat')
        worker_status = 'online' if worker_heartbeat else 'offline'
        
        # 3. çµ±è¨ˆç•¶å‰æ­£åœ¨è™•ç†çš„ä»»å‹™ï¼ˆstatus='processing'ï¼‰
        active_jobs = 0
        # æƒææ‰€æœ‰ job:status:* éµ
        status_keys = redis_client.keys('job:status:*')
        for key in status_keys:
            job_status = redis_client.hget(key, 'status')
            if job_status == 'processing':
                active_jobs += 1
        
        logger.info(f"ğŸ“Š Metrics: queue={queue_length}, worker={worker_status}, active={active_jobs}")
        
        return jsonify({
            'queue_length': queue_length,
            'worker_status': worker_status,
            'active_jobs': active_jobs
        }), 200
    
    except Exception as e:
        logger.error(f"âœ— metrics æ¥å£å¼‚å¸¸: {e}", exc_info=True)
        return jsonify({'error': 'Internal server error'}), 500


@app.route('/health', methods=['GET'])
def health():
    """å¥åº·æ£€æŸ¥æ¥å£ - æª¢æŸ¥ Redis å’Œ MySQL ç‹€æ…‹"""
    redis_status = 'healthy' if redis_client and redis_client.ping() else 'unavailable'
    
    mysql_status = 'unavailable'
    if db_client:
        mysql_status = 'healthy' if db_client.check_connection() else 'error'
    
    overall_status = 'ok' if redis_status == 'healthy' else 'degraded'
    
    return jsonify({
        'status': overall_status,
        'redis': redis_status,
        'mysql': mysql_status
    }), 200


@app.route('/api/models', methods=['GET'])
def get_models():
    """
    GET /api/models
    æƒæ ComfyUI æ¨¡å‹ç›®éŒ„ï¼Œå›å‚³å¯ç”¨æ¨¡å‹åˆ—è¡¨
    
    Response:
    {
        "models": ["model1.safetensors", "model2.ckpt"],
        "unet_models": ["unet1.safetensors"]
    }
    """
    from config import COMFYUI_CHECKPOINTS_DIR, COMFYUI_UNET_DIR
    
    models = []
    unet_models = []
    
    # æƒæ Checkpoints ç›®éŒ„
    try:
        if COMFYUI_CHECKPOINTS_DIR.exists():
            for file_path in COMFYUI_CHECKPOINTS_DIR.rglob("*"):
                if file_path.is_file() and file_path.suffix.lower() in ['.safetensors', '.ckpt']:
                    # ä½¿ç”¨ç›¸å°è·¯å¾‘ï¼ˆç›¸å°æ–¼ checkpoints ç›®éŒ„ï¼‰
                    rel_path = file_path.relative_to(COMFYUI_CHECKPOINTS_DIR)
                    models.append(str(rel_path))
            logger.info(f"âœ“ æ‰¾åˆ° {len(models)} å€‹ Checkpoint æ¨¡å‹")
        else:
            logger.warning(f"Checkpoints ç›®éŒ„ä¸å­˜åœ¨: {COMFYUI_CHECKPOINTS_DIR}")
    except Exception as e:
        logger.error(f"æƒæ Checkpoints å¤±æ•—: {e}")
    
    # æƒæ UNET ç›®éŒ„
    try:
        if COMFYUI_UNET_DIR.exists():
            for file_path in COMFYUI_UNET_DIR.rglob("*"):
                if file_path.is_file() and file_path.suffix.lower() in ['.safetensors', '.ckpt', '.pt']:
                    rel_path = file_path.relative_to(COMFYUI_UNET_DIR)
                    unet_models.append(str(rel_path))
            logger.info(f"âœ“ æ‰¾åˆ° {len(unet_models)} å€‹ UNET æ¨¡å‹")
        else:
            logger.warning(f"UNET ç›®éŒ„ä¸å­˜åœ¨: {COMFYUI_UNET_DIR}")
    except Exception as e:
        logger.error(f"æƒæ UNET å¤±æ•—: {e}")
    
    # å¦‚æœæ²’æœ‰æ‰¾åˆ°ä»»ä½•æ¨¡å‹ï¼Œè¿”å›é è¨­åˆ—è¡¨
    if not models and not unet_models:
        logger.warning("æœªæ‰¾åˆ°ä»»ä½•æ¨¡å‹ï¼Œè¿”å›é è¨­åˆ—è¡¨")
        models = ["default_model.safetensors"]
        unet_models = ["z-image/z-image-turbo-fp8-e4m3fn.safetensors"]
    
    return jsonify({
        'models': sorted(models),
        'unet_models': sorted(unet_models)
    }), 200


# ============================================
# Statistics & Monitoring Functions (Phase 3)
# ============================================

def get_redis_stats() -> dict:
    """
    ç²å– Redis çµ±è¨ˆä¿¡æ¯
    
    Returns:
        dict: åŒ…å« queue_length, memory_usage, keys_count ç­‰ä¿¡æ¯
    """
    stats = {
        'queue_length': 0,
        'memory_mb': 0,
        'total_keys': 0,
        'worker_online': False
    }
    
    if not redis_client:
        return stats
    
    try:
        # éšŠåˆ—é•·åº¦
        stats['queue_length'] = redis_client.llen(REDIS_QUEUE_NAME) or 0
        
        # Redis è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³
        info = redis_client.info('memory')
        stats['memory_mb'] = round(info.get('used_memory', 0) / (1024 * 1024), 2)
        
        # éµç¸½æ•¸
        keyspace = redis_client.info('keyspace')
        db0 = keyspace.get('db0', {})
        stats['total_keys'] = db0.get('keys', 0)
        
        # Worker ç·šä¸Šç‹€æ…‹
        stats['worker_online'] = bool(redis_client.get('worker:heartbeat'))
    except Exception as e:
        logger.warning(f"ç²å– Redis çµ±è¨ˆè³‡è¨Šå¤±æ•—: {e}")
    
    return stats

def get_task_stats() -> dict:
    """
    ç²å–ä»»å‹™çµ±è¨ˆä¿¡æ¯
    
    Returns:
        dict: åŒ…å« total_tasks, active_jobs, finished, failed ç­‰ä¿¡æ¯
    """
    stats = {
        'total_jobs': 0,
        'queued_jobs': 0,
        'processing_jobs': 0,
        'finished_jobs': 0,
        'failed_jobs': 0
    }
    
    if not redis_client:
        return stats
    
    try:
        # æƒææ‰€æœ‰ job:status:* éµ
        all_keys = redis_client.keys('job:status:*')
        stats['total_jobs'] = len(all_keys)
        
        # æŒ‰ç‹€æ…‹çµ±è¨ˆ
        for key in all_keys:
            status_info = redis_client.hgetall(key)
            status = status_info.get('status', 'unknown')
            
            if status == 'queued':
                stats['queued_jobs'] += 1
            elif status == 'processing':
                stats['processing_jobs'] += 1
            elif status == 'finished':
                stats['finished_jobs'] += 1
            elif status == 'failed':
                stats['failed_jobs'] += 1
    except Exception as e:
        logger.warning(f"ç²å–ä»»å‹™çµ±è¨ˆè³‡è¨Šå¤±æ•—: {e}")
    
    return stats

def get_stats_panel() -> Panel:
    """
    ç”Ÿæˆçµ±è¨ˆä¿¡æ¯é¢æ¿ï¼ˆRich Panelï¼‰- ç”¨ä½œåº•éƒ¨å›ºå®šç‹€æ…‹åˆ—
    
    Returns:
        rich.panel.Panel: åŒ…å«æ‰€æœ‰çµ±è¨ˆä¿¡æ¯çš„é¢æ¿
    """
    try:
        from rich.table import Table
    except ImportError:
        logger.warning("rich åº«æœªå®‰è£ï¼Œç„¡æ³•ç”Ÿæˆçµ±è¨ˆé¢æ¿")
        return Panel("çµ±è¨ˆä¿¡æ¯ä¸å¯ç”¨", title="ğŸ“Š ç³»çµ±ç‹€æ…‹")
    
    # ç²å–çµ±è¨ˆæ•¸æ“š
    redis_stats = get_redis_stats()
    task_stats = get_task_stats()
    active_users = db_client.get_active_users_count() if db_client else 0
    
    # å»ºç«‹è¡¨æ ¼
    table = Table(show_header=True, header_style="bold magenta", show_lines=False)
    table.add_column("æŒ‡æ¨™", style="cyan", width=18)
    table.add_column("æ•¸å€¼", style="green", width=15)
    
    # Redis çµ±è¨ˆ
    table.add_row("ğŸ”´ Redis éšŠåˆ—", str(redis_stats['queue_length']))
    table.add_row("ğŸ’¾ Redis è¨˜æ†¶é«”", f"{redis_stats['memory_mb']} MB")
    table.add_row("ğŸ”‘ Redis éµæ•¸", str(redis_stats['total_keys']))
    table.add_row("âš™ï¸ Worker ç‹€æ…‹", "ğŸŸ¢ åœ¨ç·š" if redis_stats['worker_online'] else "ğŸ”´ é›¢ç·š")
    
    # ä»»å‹™çµ±è¨ˆ
    table.add_row("ğŸ“‹ å¾…è™•ç†ä»»å‹™", str(task_stats['queued_jobs']))
    table.add_row("â³ è™•ç†ä¸­ä»»å‹™", str(task_stats['processing_jobs']))
    table.add_row("âœ… å·²å®Œæˆä»»å‹™", str(task_stats['finished_jobs']))
    table.add_row("âŒ å¤±æ•—ä»»å‹™", str(task_stats['failed_jobs']))
    
    # ç”¨æˆ¶çµ±è¨ˆ
    table.add_row("ğŸ‘¥ æ´»èºç”¨æˆ¶", str(active_users))
    
    # åŒ…è£ç‚º Panel
    panel = Panel(
        table,
        title="ğŸ“Š Backend Status Dashboard",
        border_style="bold blue",
        padding=(0, 1)
    )
    
    return panel

# ============================================
# Static File Serving (for generated images/videos)
# ============================================
@app.route('/outputs/<path:filename>', methods=['GET'])
def serve_output(filename):
    """
    GET /outputs/<filename>
    Serve generated images/videos from storage/outputs directory
    æ”¯æ´ .png, .jpg, .mp4 ç­‰æ ¼å¼
    é˜²æ­¢è·¯å¾‘ç©¿è¶Šæ”»æ“Š
    """
    import mimetypes
    from flask import abort
    
    # Get the absolute path to storage/outputs
    current_dir = os.path.dirname(os.path.abspath(__file__))
    outputs_dir = os.path.join(current_dir, '..', '..', 'storage', 'outputs')
    outputs_dir = os.path.abspath(outputs_dir)
    
    # ===== å®‰å…¨æ€§ï¼šé˜²æ­¢è·¯å¾‘ç©¿è¶Šæ”»æ“Š =====
    # ç¢ºä¿è«‹æ±‚çš„æª”æ¡ˆè·¯å¾‘åš´æ ¼ä½æ–¼ outputs_dir å…§
    file_path = os.path.abspath(os.path.join(outputs_dir, filename))
    if not file_path.startswith(outputs_dir):
        logger.warning(f"âš ï¸ è·¯å¾‘ç©¿è¶Šæ”»æ“Šå˜—è©¦: {filename}")
        return abort(403)  # Forbidden
    
    logger.info(f"ğŸ“ Serving file: {filename} from {outputs_dir}")
    
    # Check if file exists
    if not os.path.exists(file_path):
        logger.warning(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return abort(404)
    
    # ç¢ºä¿æ­£ç¢ºçš„ MIME Type (ç‰¹åˆ¥æ˜¯å½±ç‰‡æª”æ¡ˆ)
    mimetype, _ = mimetypes.guess_type(file_path)
    if mimetype is None:
        # æ ¹æ“šå‰¯æª”åæ‰‹å‹•è¨­å®š
        ext = os.path.splitext(filename)[1].lower()
        mime_map = {
            '.mp4': 'video/mp4',
            '.webm': 'video/webm',
            '.avi': 'video/x-msvideo',
            '.mov': 'video/quicktime',
            '.png': 'image/png',
            '.jpg': 'image/jpeg',
            '.jpeg': 'image/jpeg',
            '.gif': 'image/gif',
            '.webp': 'image/webp',
        }
        mimetype = mime_map.get(ext, 'application/octet-stream')
    
    logger.info(f"ğŸ“¹ MIME Type: {mimetype}")
    return send_from_directory(outputs_dir, filename, mimetype=mimetype)

# ============================================
# Application Entry Point
# ============================================

# Serve frontend static files
@app.route('/')
def serve_index():
    """æä¾›å‰ç«¯ index.html"""
    try:
        frontend_dir = os.path.join(os.path.dirname(__file__), '..', '..', 'frontend')
        frontend_dir = os.path.abspath(frontend_dir)
        index_path = os.path.join(frontend_dir, 'index.html')
        
        logger.info(f"Serving index.html from: {frontend_dir}")
        logger.info(f"index.html exists: {os.path.exists(index_path)}")
        
        if not os.path.exists(index_path):
            logger.error(f"index.html not found at {index_path}")
            return jsonify({"error": "Frontend not found"}), 404
            
        return send_from_directory(frontend_dir, 'index.html')
    except Exception as e:
        logger.error(f"Error serving index: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/<path:path>')
def serve_static(path):
    """æä¾›å‰ç«¯éœæ…‹æ–‡ä»¶ï¼ˆCSS, JS, åœ–ç‰‡ç­‰ï¼‰"""
    # é€™äº›è·¯å¾‘å·²ç¶“æœ‰å°ˆé–€çš„è·¯ç”±è™•ç†ï¼Œè·³é
    # æ³¨æ„: ä¸è¦ raise NotFound()ï¼Œè€Œæ˜¯ç›´æ¥ pass through
    if path.startswith('api/') or path.startswith('health') or path.startswith('outputs/'):
        # è¿”å› 404ï¼Œè®“å…¶ä»–è·¯ç”±æ¥ç®¡
        return jsonify({"error": "Not found"}), 404
    
    try:
        frontend_dir = os.path.join(os.path.dirname(__file__), '..', '..', 'frontend')
        frontend_dir = os.path.abspath(frontend_dir)
        file_path = os.path.join(frontend_dir, path)
        
        logger.info(f"Serving static file: {path} from {frontend_dir}")
        logger.info(f"File exists: {os.path.exists(file_path)}")
        
        # å˜—è©¦è¿”å›éœæ…‹æ–‡ä»¶
        if os.path.exists(file_path) and os.path.isfile(file_path):
            return send_from_directory(frontend_dir, path)
        else:
            # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¿”å› index.htmlï¼ˆæ”¯æŒ SPA è·¯ç”±ï¼‰
            logger.warning(f"File not found: {path}, serving index.html instead")
            return send_from_directory(frontend_dir, 'index.html')
            
    except Exception as e:
        logger.error(f"Error serving static file {path}: {e}")
        return jsonify({"error": str(e)}), 500

# ==========================================
# å•Ÿå‹• Flask æ‡‰ç”¨
# ==========================================
if __name__ == '__main__':
    import sys
    from threading import Thread
    from rich.live import Live
    
    def run_flask():
        """åœ¨å¾Œå°ç·šç¨‹ä¸­é‹è¡Œ Flask æ‡‰ç”¨"""
        is_windows = sys.platform.startswith('win')
        
        if is_windows:
            # Windows: ç¦ç”¨ reloader é¿å…é€²ç¨‹é€€å‡ºå•é¡Œ
            app.run(
                host='0.0.0.0', 
                port=5000, 
                debug=True, 
                use_reloader=False,
                threaded=True
            )
        else:
            # Linux/Mac: æ­£å¸¸ä½¿ç”¨ reloader
            app.run(host='0.0.0.0', port=5000, debug=True)
    
    # å•Ÿå‹• Flask æ‡‰ç”¨ç·šç¨‹ï¼ˆå®ˆè­·ç·šç¨‹ï¼‰
    logger.info("ğŸš€ Backend API å¯åŠ¨ä¸­...")
    logger.info("ğŸ“ åŒæ™‚æä¾›å‰ç«¯éœæ…‹æ–‡ä»¶æœå‹™")
    
    # å•Ÿå‹•ç‹€æ…‹å¿«ç…§ç·šç¨‹ï¼ˆç›£æ§å„€è¡¨æ¿å°‡ç½®é ‚ï¼Œæ¯ 5 ç§’æ›´æ–°ä¸€æ¬¡ï¼‰
    logger.info("âœ“ ç‹€æ…‹ç›£æ§å·²å•Ÿå‹•ï¼ˆå„€è¡¨æ¿ç½®é ‚ï¼‰")
    
    def live_status_monitor():
        """å¯¦æ™‚ç›£æ§ç‹€æ…‹ - ä½¿ç”¨ Live é¡¯ç¤ºç½®é ‚å„€è¡¨æ¿ï¼Œæ—¥èªŒå¾åº•éƒ¨æ»¾å‹•"""
        from rich.live import Live
        from rich.console import Group
        from rich.text import Text
        
        try:
            # Phase 9: ä½¿ç”¨ Live å›ºå®šé¡¯ç¤ºåœ¨é ‚éƒ¨ï¼Œæ—¥èªŒå¾€ä¸‹æ»¾å‹•
            # screen=False ç¢ºä¿ä¸æ¸…ç©ºçµ‚ç«¯ï¼Œtransient=False ç¢ºä¿ä¸æœƒæ¶ˆå¤±
            with Live(
                get_stats_panel(), 
                refresh_per_second=0.2,  # æ¯ç§’åˆ·æ–° 0.2 æ¬¡ï¼ˆ5 ç§’ä¸€æ¬¡ï¼‰
                screen=False,  # ä¸å…¨å±ï¼Œå…è¨±æ—¥èªŒåœ¨ä¸‹æ–¹æ»¾å‹•
                transient=False,  # ä¿ç•™å„€è¡¨æ¿ï¼Œä¸æœƒæ¶ˆå¤±
                vertical_overflow="visible"  # å…è¨±å…§å®¹æº¢å‡ºï¼ˆæ—¥èªŒä¸æœƒè¢«æˆªæ–·ï¼‰
            ) as live:
                while True:
                    time.sleep(5)  # æ¯ 5 ç§’æ›´æ–°ä¸€æ¬¡ç‹€æ…‹é¢æ¿
                    live.update(get_stats_panel())
        except KeyboardInterrupt:
            pass
        except Exception as e:
            logger.error(f"ç‹€æ…‹ç›£æ§ç•°å¸¸: {e}")
    
    status_thread = Thread(target=live_status_monitor, daemon=True)
    status_thread.start()
    
    flask_thread = Thread(target=run_flask, daemon=True)
    flask_thread.start()
    logger.info("âœ“ Flask æ‡‰ç”¨ç·šç¨‹å·²å•Ÿå‹•\n")
    
    # çµ¦ Flask ä¸€äº›æ™‚é–“åˆå§‹åŒ–
    time.sleep(2)
    
    logger.info("âœ“ ç³»çµ±å·²å°±ç·’ï¼Œç›£æ§æ—¥èªŒæŒçºŒè¼¸å‡ºä¸­...")
    
    # ä¿æŒä¸»ç·šç¨‹æ´»èº
    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        logger.info("\nâ¹ï¸ æ­£åœ¨é—œé–‰ Backend...")
        time.sleep(1)
        logger.info("âœ“ Backend å·²å„ªé›…é—œé–‰")
        sys.exit(0)