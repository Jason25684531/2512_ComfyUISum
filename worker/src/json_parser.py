"""
JSON Parser for ComfyUI Workflow
================================
å‹•æ…‹è§£æä¸¦ä¿®æ”¹ ComfyUI workflow JSON æª”æ¡ˆã€‚
æ”¯æ´ Aspect Ratioã€Modelã€Promptã€Seed ç­‰åƒæ•¸æ³¨å…¥ã€‚
"""

import json
import os
import copy
from pathlib import Path

# ==========================================
# Aspect Ratio æ˜ å°„è¡¨ (SDXL æœ€ä½³è§£æåº¦)
# ==========================================
ASPECT_RATIO_MAP = {
    "1:1":  {"width": 1024, "height": 1024},  # æ–¹å½¢
    "16:9": {"width": 1216, "height": 832},   # é›»å½±å¯¬éŠ€å¹•
    "9:16": {"width": 832, "height": 1216},   # æ‰‹æ©Ÿç›´å¼
    "2:3":  {"width": 832, "height": 1248},   # äººåƒç›´å¼
}
DEFAULT_RESOLUTION = {"width": 1024, "height": 1024}

# ==========================================
# Model æ˜ å°„è¡¨
# âš ï¸ è«‹æ ¹æ“šæ‚¨çš„ ComfyUI models è³‡æ–™å¤¾å…§çš„å¯¦éš›æª”åä¿®æ”¹ï¼
# è·¯å¾‘æ ¼å¼ï¼šç›¸å°æ–¼ ComfyUI/models/checkpoints/ æˆ– unet/
# ==========================================
MODEL_MAP = {
    # UNET æ¨¡å‹ (ç”¨æ–¼ UNETLoader)
    "turbo_fp8": "z-image\\z-image-turbo-fp8-e4m3fn.safetensors",
    "z_image_turbo": "z-image\\z-image-turbo-fp8-e4m3fn.safetensors",
    
    # Checkpoint æ¨¡å‹ (ç”¨æ–¼ CheckpointLoaderSimple)
    # "sdxl_base": "sd_xl_base_1.0.safetensors",
    # "sdxl_turbo": "sd_xl_turbo_1.0.safetensors",
    # "dreamshaper": "dreamshaper_8.safetensors",
}

# Workflow æª”æ¡ˆæ˜ å°„
WORKFLOW_MAP = {
    "text_to_image": "text_to_image_z_image_turbo_fp8_1222.json",
    "face_swap": "face_swap_qwen_2509_gguf_1222.json",
    "multi_image_blend": "multi_image_blend_qwen_2509_gguf_1222.json",
    "single_image_edit": "single_image_edit_qwen_2509_gguf_1222.json",
    "sketch_to_image": "sketch_to_image_qwen_2509_gguf_1222.json",
    "virtual_human": "InfiniteTalk_IndexTTS_2.json",
}

# ==========================================
# åœ–ç‰‡ç¯€é»æ˜ å°„è¡¨
# å®šç¾©æ¯å€‹å·¥ä½œæµçš„ LoadImage ç¯€é»å°æ‡‰å“ªå€‹å‰ç«¯ä¸Šå‚³æ¬„ä½
# âš ï¸ æ¬„ä½åç¨±å¿…é ˆèˆ‡å‰ç«¯ toolConfig ä¸­çš„ uploads.id ä¸€è‡´ï¼
# ==========================================
IMAGE_NODE_MAP = {
    "face_swap": {
        # ç¯€é» ID -> å‰ç«¯æ¬„ä½åç¨±
        "501": "source",   # é ­ (è¦æ›ä¸Šå»çš„è‡‰)
        "502": "target",   # èº«é«” (ç›®æ¨™åœ–ç‰‡)
    },
    "multi_image_blend": {
        "120": "source",   # åœ–1 (å°æ‡‰å‰ç«¯ Image A)
        "121": "target",   # åœ–2 (å°æ‡‰å‰ç«¯ Image B)
        "122": "extra",    # åœ–3 (å°æ‡‰å‰ç«¯ Image C)
    },
    "sketch_to_image": {
        "120": "input",    # è‰ç¨¿åœ–
    },
    "single_image_edit": {
        "120": "input",    # åŸåœ–
    },
    "text_to_image": {},   # ä¸éœ€è¦åœ–ç‰‡
    "virtual_human": {
        "284": "avatar",   # è™›æ“¬äººåƒè€ƒåœ– (LoadImage)
    },
}

# ==========================================
# éŸ³è¨Šç¯€é»æ˜ å°„è¡¨ (ç”¨æ–¼ virtual_human ç­‰å·¥ä½œæµ)
# ==========================================
AUDIO_NODE_MAP = {
    "virtual_human": {
        "node_id": "311",    # LoadAudio ç¯€é» ID
        "input_key": "audio" # ç¯€é» inputs ä¸­çš„åƒæ•¸å
    }
}


def get_workflow_path(workflow_name: str) -> Path:
    """
    å–å¾— workflow JSON æª”æ¡ˆè·¯å¾‘
    """
    from config import WORKFLOW_DIR
    filename = WORKFLOW_MAP.get(workflow_name, f"{workflow_name}.json")
    return WORKFLOW_DIR / filename


def load_workflow(workflow_name: str) -> dict:
    """
    è¼‰å…¥ workflow JSON æ¨¡æ¿
    """
    workflow_path = get_workflow_path(workflow_name)
    
    if not workflow_path.exists():
        raise FileNotFoundError(f"Workflow æª”æ¡ˆä¸å­˜åœ¨: {workflow_path}")
    
    with open(workflow_path, "r", encoding="utf-8") as f:
        return json.load(f)


def find_node_by_class(workflow: dict, class_type: str) -> tuple:
    """
    æ ¹æ“š class_type æ‰¾åˆ°ç¯€é»
    Returns: (node_id, node_data) or (None, None)
    """
    for node_id, node_data in workflow.items():
        if isinstance(node_data, dict) and node_data.get("class_type") == class_type:
            return node_id, node_data
    return None, None


def find_nodes_by_class(workflow: dict, class_type: str) -> list:
    """
    æ‰¾åˆ°æ‰€æœ‰ç¬¦åˆ class_type çš„ç¯€é»
    Returns: [(node_id, node_data), ...]
    """
    nodes = []
    for node_id, node_data in workflow.items():
        if isinstance(node_data, dict) and node_data.get("class_type") == class_type:
            nodes.append((node_id, node_data))
    return nodes


def parse_workflow(
    workflow_name: str,
    prompt: str = "",
    seed: int = -1,
    aspect_ratio: str = "1:1",
    model: str = "turbo_fp8",
    batch_size: int = 1,
    image_files: dict = None,
    audio_file: str = None,
    **kwargs
) -> dict:
    """
    è§£æä¸¦æ³¨å…¥åƒæ•¸åˆ° workflow
    
    Args:
        workflow_name: workflow åç¨± (å¦‚ "text_to_image", "virtual_human")
        prompt: æ­£å‘æç¤ºè©
        seed: éš¨æ©Ÿç¨®å­ (-1 ç‚ºéš¨æ©Ÿ)
        aspect_ratio: ç•«é¢æ¯”ä¾‹ ("1:1", "16:9", "9:16", "2:3")
        model: æ¨¡å‹åç¨±
        batch_size: æ‰¹æ¬¡æ•¸é‡
        image_files: åœ–ç‰‡æª”åæ˜ å°„ {"source": "xxx.png", "target": "yyy.png"}
        audio_file: éŸ³è¨Šæª”å (ç”¨æ–¼ virtual_human å·¥ä½œæµ)
    
    Returns:
        ä¿®æ”¹å¾Œçš„ workflow dict
    """
    if image_files is None:
        image_files = {}
    # è¼‰å…¥åŸå§‹ workflow
    workflow = load_workflow(workflow_name)
    workflow = copy.deepcopy(workflow)  # é¿å…ä¿®æ”¹åŸå§‹è³‡æ–™
    
    # å–å¾—è§£æåº¦
    resolution = ASPECT_RATIO_MAP.get(aspect_ratio, DEFAULT_RESOLUTION)
    width = resolution["width"]
    height = resolution["height"]
    
    # è™•ç† seed (-1 è¡¨ç¤ºéš¨æ©Ÿ)
    if seed == -1:
        import random
        seed = random.randint(0, 2**32 - 1)
    
    print(f"[Parser] è§£æåº¦: {width}x{height}, Seed: {seed}, Model: {model}")
    
    # ==========================================
    # æ³¨å…¥ Prompt (æ”¯æ´å¤šç¨®ç¯€é»é¡å‹)
    # ==========================================
    prompt_injected = False
    
    # 1. å˜—è©¦ CLIPTextEncode (æ¨™æº– SDXL workflow)
    positive_nodes = find_nodes_by_class(workflow, "CLIPTextEncode")
    for node_id, node in positive_nodes:
        title = node.get("_meta", {}).get("title", "")
        if "Positive" in title or "positive" in title.lower():
            node["inputs"]["text"] = prompt
            print(f"[Parser] æ³¨å…¥ Prompt åˆ° CLIPTextEncode ç¯€é» {node_id}")
            prompt_injected = True
            break
    else:
        # å¦‚æœæ²’æ‰¾åˆ°æ¨™é¡Œï¼Œå˜—è©¦ç¬¬ä¸€å€‹ CLIPTextEncode
        if positive_nodes:
            positive_nodes[0][1]["inputs"]["text"] = prompt
            print(f"[Parser] æ³¨å…¥ Prompt åˆ°ç¬¬ä¸€å€‹ CLIPTextEncode ç¯€é»")
            prompt_injected = True
    
    # 2. å˜—è©¦ StringConstantMultiline (ç”¨æ–¼ face_swap ç­‰éœ€è¦ç”¨æˆ¶è¼¸å…¥çš„ workflow)
    # æ³¨æ„ï¼šä¸è¦æ³¨å…¥åˆ° title åŒ…å« "Trigger" æˆ– "trigger" çš„ç¯€é»ï¼Œé‚£äº›æ˜¯é è¨­å…§å®¹
    if not prompt_injected:
        string_nodes = find_nodes_by_class(workflow, "StringConstantMultiline")
        for node_id, node in string_nodes:
            title = node.get("_meta", {}).get("title", "").lower()
            # è·³éåŒ…å« trigger çš„ç¯€é»ï¼ˆé‚£æ˜¯é è¨­å›ºå®šçš„ promptï¼‰
            if "trigger" not in title:
                if "inputs" in node and "string" in node["inputs"]:
                    node["inputs"]["string"] = prompt
                    print(f"[Parser] æ³¨å…¥ Prompt åˆ° StringConstantMultiline ç¯€é» {node_id} (title: {node.get('_meta', {}).get('title', '')})")
                    prompt_injected = True
                    break
    
    # 3. å˜—è©¦ TextEncodeQwenImageEditPlus (Qwen Image Edit workflow)
    if not prompt_injected:
        qwen_nodes = find_nodes_by_class(workflow, "TextEncodeQwenImageEditPlus")
        for node_id, node in qwen_nodes:
            title = node.get("_meta", {}).get("title", "").lower()
            # åªæ³¨å…¥åˆ° Positive ç¯€é» (é€šå¸¸ Negative ç¯€é»çš„ prompt ç‚ºç©º)
            if "negative" not in title:
                if "inputs" in node and "prompt" in node["inputs"]:
                    node["inputs"]["prompt"] = prompt
                    print(f"[Parser] æ³¨å…¥ Prompt åˆ° TextEncodeQwenImageEditPlus ç¯€é» {node_id}")
                    prompt_injected = True
                    break
        
        if not prompt_injected and qwen_nodes:
            # å¦‚æœæ‰¾ä¸åˆ°æ˜ç¢ºçš„ Positiveï¼Œå˜—è©¦ç¬¬ä¸€å€‹æœ‰ prompt è¼¸å…¥çš„ç¯€é»
            for node_id, node in qwen_nodes:
                if "inputs" in node and "prompt" in node["inputs"]:
                    # æª¢æŸ¥é€™å€‹ç¯€é»çš„ prompt æ˜¯å¦ä¸ç‚ºç©º (è¡¨ç¤ºæ˜¯ Positive)
                    if node["inputs"]["prompt"] or node["inputs"]["prompt"] == "":
                        node["inputs"]["prompt"] = prompt
                        print(f"[Parser] æ³¨å…¥ Prompt åˆ° TextEncodeQwenImageEditPlus ç¯€é» {node_id} (fallback)")
                        prompt_injected = True
                        break
    
    if not prompt_injected:
        print(f"[Parser] âš ï¸ æœªæ‰¾åˆ°å¯æ³¨å…¥ Prompt çš„ç¯€é»")
    
    # ==========================================
    # æ³¨å…¥ Seed (KSampler)
    # ==========================================
    sampler_id, sampler_node = find_node_by_class(workflow, "KSampler")
    if sampler_node:
        sampler_node["inputs"]["seed"] = seed
        print(f"[Parser] æ³¨å…¥ Seed åˆ° KSampler ç¯€é» {sampler_id}")
    
    # ==========================================
    # æ³¨å…¥ Resolution (EmptySD3LatentImage / EmptyLatentImage)
    # ==========================================
    latent_classes = ["EmptySD3LatentImage", "EmptyLatentImage"]
    for class_type in latent_classes:
        latent_id, latent_node = find_node_by_class(workflow, class_type)
        if latent_node:
            latent_node["inputs"]["width"] = width
            latent_node["inputs"]["height"] = height
            latent_node["inputs"]["batch_size"] = batch_size
            print(f"[Parser] æ³¨å…¥è§£æåº¦ {width}x{height} åˆ° {class_type} ç¯€é» {latent_id}")
            break
    
    # ==========================================
    # æ³¨å…¥ Model (UNETLoader / CheckpointLoaderSimple)
    # ==========================================
    model_filename = MODEL_MAP.get(model)
    
    if model_filename:
        # å˜—è©¦ UNETLoader
        unet_id, unet_node = find_node_by_class(workflow, "UNETLoader")
        if unet_node:
            unet_node["inputs"]["unet_name"] = model_filename
            print(f"[Parser] æ³¨å…¥æ¨¡å‹ {model_filename} åˆ° UNETLoader ç¯€é» {unet_id}")
        
        # å˜—è©¦ CheckpointLoaderSimple
        ckpt_id, ckpt_node = find_node_by_class(workflow, "CheckpointLoaderSimple")
        if ckpt_node:
            ckpt_node["inputs"]["ckpt_name"] = model_filename
            print(f"[Parser] æ³¨å…¥æ¨¡å‹ {model_filename} åˆ° CheckpointLoaderSimple ç¯€é» {ckpt_id}")
    else:
        print(f"[Parser] âš ï¸ æœªçŸ¥æ¨¡å‹: {model}ï¼Œä½¿ç”¨ workflow é è¨­å€¼")
    
    # ==========================================
    # æ³¨å…¥åœ–ç‰‡ (LoadImage ç¯€é»)
    # ==========================================
    node_map = IMAGE_NODE_MAP.get(workflow_name, {})
    
    if node_map and image_files:
        print(f"[Parser] æº–å‚™æ³¨å…¥åœ–ç‰‡ï¼Œæ˜ å°„è¡¨: {node_map}")
        print(f"[Parser] æ”¶åˆ°çš„åœ–ç‰‡æª”æ¡ˆ: {image_files}")
        
        for node_id, field_name in node_map.items():
            if field_name in image_files:
                filename = image_files[field_name]
                
                # æ‰¾åˆ°å°æ‡‰çš„ LoadImage ç¯€é»
                if node_id in workflow:
                    node = workflow[node_id]
                    if "inputs" in node:
                        old_image = node["inputs"].get("image", "")
                        node["inputs"]["image"] = filename
                        print(f"[Parser] âœ… ç¯€é» {node_id}: {old_image!r} -> {filename!r}")
                    else:
                        print(f"[Parser] âš ï¸ ç¯€é» {node_id} æ²’æœ‰ inputs")
                else:
                    print(f"[Parser] âš ï¸ æ‰¾ä¸åˆ°ç¯€é» {node_id}")
            else:
                print(f"[Parser] âš ï¸ ç¼ºå°‘åœ–ç‰‡æ¬„ä½: {field_name}")
    elif node_map:
        print(f"[Parser] âš ï¸ æ­¤å·¥ä½œæµéœ€è¦åœ–ç‰‡ä½†æœªæä¾›: {list(node_map.values())}")
    
    # ==========================================
    # æ³¨å…¥éŸ³è¨Š (LoadAudio ç¯€é») - Phase 7 æ–°å¢
    # ==========================================
    audio_config = AUDIO_NODE_MAP.get(workflow_name)
    
    if audio_config and audio_file:
        node_id = audio_config.get("node_id")
        input_key = audio_config.get("input_key", "audio")
        
        if node_id and node_id in workflow:
            node = workflow[node_id]
            if "inputs" in node:
                old_audio = node["inputs"].get(input_key, "")
                node["inputs"][input_key] = audio_file
                print(f"[Parser] ğŸµ Injecting audio file: {audio_file} into node {node_id}")
                print(f"[Parser] âœ… éŸ³è¨Šç¯€é» {node_id}: {old_audio!r} -> {audio_file!r}")
            else:
                print(f"[Parser] âš ï¸ éŸ³è¨Šç¯€é» {node_id} æ²’æœ‰ inputs")
        elif node_id:
            print(f"[Parser] âš ï¸ æ‰¾ä¸åˆ°éŸ³è¨Šç¯€é» {node_id}")
    elif audio_config and not audio_file:
        print(f"[Parser] â„¹ï¸ å·¥ä½œæµ {workflow_name} æ”¯æ´éŸ³è¨Šæ³¨å…¥ï¼Œä½†æœªæä¾›éŸ³è¨Šæª”æ¡ˆï¼Œä½¿ç”¨é è¨­å€¼")
    
    return workflow


# ==========================================
# æ¸¬è©¦ç”¨
# ==========================================
if __name__ == "__main__":
    # æ¸¬è©¦ parse_workflow
    try:
        workflow = parse_workflow(
            workflow_name="text_to_image",
            prompt="A beautiful sunset over mountains",
            seed=12345,
            aspect_ratio="16:9",
            model="turbo_fp8",
            batch_size=1
        )
        print("\n[Test] Workflow è§£ææˆåŠŸï¼")
        print(json.dumps(workflow, indent=2, ensure_ascii=False)[:500] + "...")
    except Exception as e:
        print(f"[Test] éŒ¯èª¤: {e}")
