"""
JSON Parser for ComfyUI Workflow
================================
å‹•æ…‹è§£æä¸¦ä¿®æ”¹ ComfyUI workflow JSON æª”æ¡ˆã€‚
æ”¯æ´ Aspect Ratioã€Modelã€Promptã€Seed ç­‰åƒæ•¸æ³¨å…¥ã€‚
"""

import json
import os
import copy
from pathlib import Path

# ==========================================
# Aspect Ratio æ˜ å°„è¡¨ (SDXL æœ€ä½³è§£æåº¦)
# ==========================================
ASPECT_RATIO_MAP = {
    "1:1":  {"width": 1024, "height": 1024},  # æ–¹å½¢
    "16:9": {"width": 1216, "height": 832},   # é›»å½±å¯¬éŠ€å¹•
    "9:16": {"width": 832, "height": 1216},   # æ‰‹æ©Ÿç›´å¼
    "2:3":  {"width": 832, "height": 1248},   # äººåƒç›´å¼
}
DEFAULT_RESOLUTION = {"width": 1024, "height": 1024}

# ==========================================
# Model æ˜ å°„è¡¨
# âš ï¸ è«‹æ ¹æ“šæ‚¨çš„ ComfyUI models è³‡æ–™å¤¾å…§çš„å¯¦éš›æª”åä¿®æ”¹ï¼
# è·¯å¾‘æ ¼å¼ï¼šç›¸å°æ–¼ ComfyUI/models/checkpoints/ æˆ– unet/
# ==========================================
MODEL_MAP = {
    # UNET æ¨¡å‹ (ç”¨æ–¼ UNETLoader)
    "turbo_fp8": "z-image\\z-image-turbo-fp8-e4m3fn.safetensors",
    "z_image_turbo": "z-image\\z-image-turbo-fp8-e4m3fn.safetensors",
    
    # Checkpoint æ¨¡å‹ (ç”¨æ–¼ CheckpointLoaderSimple)
    # "sdxl_base": "sd_xl_base_1.0.safetensors",
    # "sdxl_turbo": "sd_xl_turbo_1.0.safetensors",
    # "dreamshaper": "dreamshaper_8.safetensors",
}

# Workflow æª”æ¡ˆæ˜ å°„
WORKFLOW_MAP = {
    "text_to_image": "text_to_image_z_image_turbo_fp8_1222.json",
    "face_swap": "face_swap_qwen_2509_gguf_1222.json",
    "multi_image_blend": "multi_image_blend_qwen_2509_gguf_1222.json",
    "single_image_edit": "single_image_edit_qwen_2509_gguf_1222.json",
    "sketch_to_image": "sketch_to_image_qwen_2509_gguf_1222.json",
    "virtual_human": "InfiniteTalk_IndexTTS_2.json",
    "veo3_long_video": "Veo3_VideoConnection.json",
    "image_to_video": "Veo3_VideoConnection.json",  # å–®æ®µæ¨¡å¼ä¹Ÿä½¿ç”¨ Veo3
}

# ==========================================
# åœ–ç‰‡ç¯€é»æ˜ å°„è¡¨
# å®šç¾©æ¯å€‹å·¥ä½œæµçš„ LoadImage ç¯€é»å°æ‡‰å“ªå€‹å‰ç«¯ä¸Šå‚³æ¬„ä½
# âš ï¸ æ¬„ä½åç¨±å¿…é ˆèˆ‡å‰ç«¯ toolConfig ä¸­çš„ uploads.id ä¸€è‡´ï¼
# ==========================================
IMAGE_NODE_MAP = {
    "face_swap": {
        # ç¯€é» ID -> å‰ç«¯æ¬„ä½åç¨±
        "501": "source",   # é ­ (è¦æ›ä¸Šå»çš„è‡‰)
        "502": "target",   # èº«é«” (ç›®æ¨™åœ–ç‰‡)
    },
    "multi_image_blend": {
        # ç¯€é» ID å°æ‡‰ multi_image_blend_qwen_2509_gguf_1222.json
        "78": "source",    # æ¨¡ç‰¹åœ– (å°æ‡‰å‰ç«¯ Image A)
        "436": "target",   # è¡Œæç®±åœ– (å°æ‡‰å‰ç«¯ Image B)
        "437": "extra",    # å ´æ™¯åœ– (å°æ‡‰å‰ç«¯ Image C)
    },
    "sketch_to_image": {
        "120": "input",    # è‰ç¨¿åœ–
    },
    "single_image_edit": {
        "120": "input",    # åŸåœ–
    },
    "text_to_image": {},   # ä¸éœ€è¦åœ–ç‰‡
    "virtual_human": {
        "284": "avatar",   # è™›æ“¬äººåƒè€ƒåœ– (LoadImage)
    },
    "veo3_long_video": {
        # Veo3 Long Video: 5 å€‹ LoadImage ç¯€é»å°æ‡‰ Shot 1-5
        "6": "shot_0",     # Shot 1 åœ–ç‰‡
        "20": "shot_1",    # Shot 2 åœ–ç‰‡
        "30": "shot_2",    # Shot 3 åœ–ç‰‡
        "40": "shot_3",    # Shot 4 åœ–ç‰‡
        "50": "shot_4",    # Shot 5 åœ–ç‰‡
    },
    "image_to_video": {
        "6": "shot_0",     # å–®æ®µæ¨¡å¼ä¹Ÿä½¿ç”¨ Shot 1
    },
}

# ==========================================
# éŸ³è¨Šç¯€é»æ˜ å°„è¡¨ (ç”¨æ–¼ virtual_human ç­‰å·¥ä½œæµ)
# ==========================================
AUDIO_NODE_MAP = {
    "virtual_human": {
        "node_id": "311",    # LoadAudio ç¯€é» ID
        "input_key": "audio" # ç¯€é» inputs ä¸­çš„åƒæ•¸å
    }
}


def get_workflow_path(workflow_name: str) -> Path:
    """
    å–å¾— workflow JSON æª”æ¡ˆè·¯å¾‘
    å„ªå…ˆå¾ config.json è®€å–ï¼Œè‹¥ä¸å­˜åœ¨å‰‡ä½¿ç”¨ WORKFLOW_MAP
    """
    from config import WORKFLOW_DIR, WORKFLOW_CONFIG_PATH
    import json
    
    # å˜—è©¦å¾ config.json è®€å–æ–‡ä»¶å
    if WORKFLOW_CONFIG_PATH.exists():
        try:
            with open(WORKFLOW_CONFIG_PATH, 'r', encoding='utf-8') as f:
                config_data = json.load(f)
            
            workflow_config = config_data.get(workflow_name, {})
            if 'file' in workflow_config:
                filename = workflow_config['file']
                print(f"[Parser] å¾ config.json è®€å– workflow æ–‡ä»¶: {filename}")
                return WORKFLOW_DIR / filename
        except Exception as e:
            print(f"[Parser] âš ï¸ è®€å– config.json å¤±æ•—: {e}")
    
    # Fallback: ä½¿ç”¨ WORKFLOW_MAP
    filename = WORKFLOW_MAP.get(workflow_name, f"{workflow_name}.json")
    return WORKFLOW_DIR / filename


def load_workflow(workflow_name: str) -> dict:
    """
    è¼‰å…¥ workflow JSON æ¨¡æ¿
    """
    workflow_path = get_workflow_path(workflow_name)
    
    if not workflow_path.exists():
        raise FileNotFoundError(f"Workflow æª”æ¡ˆä¸å­˜åœ¨: {workflow_path}")
    
    with open(workflow_path, "r", encoding="utf-8") as f:
        return json.load(f)


def find_node_by_class(workflow: dict, class_type: str) -> tuple:
    """
    æ ¹æ“š class_type æ‰¾åˆ°ç¯€é»
    Returns: (node_id, node_data) or (None, None)
    """
    for node_id, node_data in workflow.items():
        if isinstance(node_data, dict) and node_data.get("class_type") == class_type:
            return node_id, node_data
    return None, None


def find_nodes_by_class(workflow: dict, class_type: str) -> list:
    """
    æ‰¾åˆ°æ‰€æœ‰ç¬¦åˆ class_type çš„ç¯€é»
    Returns: [(node_id, node_data), ...]
    """
    nodes = []
    for node_id, node_data in workflow.items():
        if isinstance(node_data, dict) and node_data.get("class_type") == class_type:
            nodes.append((node_id, node_data))
    return nodes


def trim_veo3_workflow(workflow: dict, image_files: dict) -> dict:
    """
    æ ¹æ“šå¯¦éš›ä¸Šå‚³çš„åœ–ç‰‡æ•¸é‡ï¼Œå‹•æ…‹è£å‰ª Veo3 Long Video å·¥ä½œæµ
    
    Veo3 å·¥ä½œæµçµæ§‹ (æ¯å€‹ Shot çš„ç¯€é»):
    - Shot 1: ç¯€é» 6 (LoadImage), 10 (VeoVideoGenerator), 11 (VHS_VideoCombine)
    - Shot 2: ç¯€é» 20 (LoadImage), 21 (VeoVideoGenerator), 22 (VHS_VideoCombine)
    - Shot 3: ç¯€é» 30 (LoadImage), 31 (VeoVideoGenerator), 32 (VHS_VideoCombine)
    - Shot 4: ç¯€é» 40 (LoadImage), 41 (VeoVideoGenerator), 42 (VHS_VideoCombine)
    - Shot 5: ç¯€é» 50 (LoadImage), 51 (VeoVideoGenerator), 52 (VHS_VideoCombine)
    - ImageBatch éˆ: 100 -> 101 -> 102 -> 103 -> 110 (æœ€çµ‚è¼¸å‡º)
    
    Args:
        workflow: åŸå§‹å·¥ä½œæµ
        image_files: åœ–ç‰‡æª”æ¡ˆæ˜ å°„ {"shot_0": "xxx.png", "shot_1": "yyy.png", ...}
    
    Returns:
        è£å‰ªå¾Œçš„å·¥ä½œæµ
    """
    # ç¢ºå®šæœ‰å“ªäº› shots
    valid_shots = []
    for i in range(5):
        shot_key = f"shot_{i}"
        if shot_key in image_files and image_files[shot_key]:
            valid_shots.append(i)
    
    shot_count = len(valid_shots)
    print(f"[Parser] Veo3 å‹•æ…‹è£å‰ª: åµæ¸¬åˆ° {shot_count} å€‹æœ‰æ•ˆ shots: {valid_shots}")
    
    if shot_count == 0:
        print("[Parser] âš ï¸ æ²’æœ‰æœ‰æ•ˆçš„åœ–ç‰‡ï¼Œè¿”å›åŸå§‹å·¥ä½œæµ")
        return workflow
    
    if shot_count == 5:
        print("[Parser] æ‰€æœ‰ 5 å€‹ shots éƒ½æœ‰åœ–ç‰‡ï¼Œä¸éœ€è¦è£å‰ª")
        return workflow
    
    # Shot ç¯€é»æ˜ å°„ (å°æ‡‰ Veo3_VideoConnection.json)
    # æ³¨æ„ï¼šæ­¤ workflow æ²’æœ‰ç¨ç«‹çš„ VHS_VideoCombine ç¯€é»ï¼Œåªæœ‰æœ€çµ‚è¼¸å‡ºç¯€é» 110
    shot_nodes = {
        0: {"load": "6", "gen": "10"},   # Shot 1
        1: {"load": "20", "gen": "21"},  # Shot 2
        2: {"load": "30", "gen": "31"},  # Shot 3
        3: {"load": "40", "gen": "41"},  # Shot 4
        4: {"load": "50", "gen": "51"},  # Shot 5
    }
    
    # åˆªé™¤æ²’æœ‰åœ–ç‰‡çš„ Shot ç¯€é»
    nodes_to_remove = []
    for i in range(5):
        if i not in valid_shots:
            nodes = shot_nodes[i]
            nodes_to_remove.extend([nodes["load"], nodes["gen"]])
            print(f"[Parser] ç§»é™¤ Shot {i+1} ç¯€é»: {nodes}")
    
    for node_id in nodes_to_remove:
        if node_id in workflow:
            del workflow[node_id]
    
    # é‡å»º ImageBatch éˆ (åªé€£æ¥æœ‰æ•ˆçš„ shots)
    # åŸå§‹éˆ: 100(10+21) -> 101(100+31) -> 102(101+41) -> 103(102+51) -> 110
    
    # ç§»é™¤åŸæœ‰çš„ ImageBatch ç¯€é»
    for node_id in ["100", "101", "102", "103"]:
        if node_id in workflow:
            del workflow[node_id]
    
    # ç²å–æœ‰æ•ˆ shots çš„ generator ç¯€é» ID (è¼¸å‡ºå½±ç‰‡å¹€)
    valid_gen_nodes = [shot_nodes[i]["gen"] for i in valid_shots]
    print(f"[Parser] æœ‰æ•ˆçš„ generator ç¯€é»: {valid_gen_nodes}")
    
    if shot_count == 1:
        # åªæœ‰ä¸€å€‹ shotï¼Œç›´æ¥é€£æ¥åˆ°æœ€çµ‚è¼¸å‡º
        if "110" in workflow:
            workflow["110"]["inputs"]["images"] = [valid_gen_nodes[0], 0]
            print(f"[Parser] å–®ä¸€ shot æ¨¡å¼: ç¯€é» 110 ç›´æ¥é€£æ¥åˆ° {valid_gen_nodes[0]}")
    else:
        # å¤šå€‹ shotsï¼Œé‡å»º ImageBatch éˆ
        # ä½¿ç”¨ç¯€é» ID 100, 101, 102... ä¾†å»ºç«‹éˆ
        batch_node_id = 100
        
        # ç¬¬ä¸€å€‹ batch: é€£æ¥å‰å…©å€‹ generator
        workflow[str(batch_node_id)] = {
            "inputs": {
                "image1": [valid_gen_nodes[0], 0],
                "image2": [valid_gen_nodes[1], 0]
            },
            "class_type": "ImageBatch",
            "_meta": {"title": "Batch Images (Dynamic)"}
        }
        print(f"[Parser] å»ºç«‹ ImageBatch {batch_node_id}: {valid_gen_nodes[0]} + {valid_gen_nodes[1]}")
        
        # å¾ŒçºŒçš„ batch: é€£æ¥å‰ä¸€å€‹ batch å’Œä¸‹ä¸€å€‹ generator
        for i in range(2, shot_count):
            prev_batch_id = str(batch_node_id)
            batch_node_id += 1
            
            workflow[str(batch_node_id)] = {
                "inputs": {
                    "image1": [prev_batch_id, 0],
                    "image2": [valid_gen_nodes[i], 0]
                },
                "class_type": "ImageBatch",
                "_meta": {"title": f"Batch Images (Dynamic {i})"}
            }
            print(f"[Parser] å»ºç«‹ ImageBatch {batch_node_id}: {prev_batch_id} + {valid_gen_nodes[i]}")
        
        # æœ€çµ‚è¼¸å‡ºç¯€é»é€£æ¥åˆ°æœ€å¾Œä¸€å€‹ batch
        if "110" in workflow:
            workflow["110"]["inputs"]["images"] = [str(batch_node_id), 0]
            print(f"[Parser] ç¯€é» 110 é€£æ¥åˆ°æœ€å¾Œçš„ ImageBatch: {batch_node_id}")
    
    return workflow


def parse_workflow(
    workflow_name: str,
    prompt: str = "",
    prompts: list = None,  # Veo3 Long Video: å¤šæ®µ prompts
    seed: int = -1,
    aspect_ratio: str = "1:1",
    model: str = "turbo_fp8",
    batch_size: int = 1,
    image_files: dict = None,
    audio_file: str = None,
    **kwargs
) -> dict:
    """
    è§£æä¸¦æ³¨å…¥åƒæ•¸åˆ° workflow
    
    Args:
        workflow_name: workflow åç¨± (å¦‚ "text_to_image", "virtual_human", "veo3_long_video")
        prompt: æ­£å‘æç¤ºè©
        prompts: å¤šæ®µæç¤ºè©åˆ—è¡¨ (ç”¨æ–¼ veo3_long_video)
        seed: éš¨æ©Ÿç¨®å­ (-1 ç‚ºéš¨æ©Ÿ)
        aspect_ratio: ç•«é¢æ¯”ä¾‹ ("1:1", "16:9", "9:16", "2:3")
        model: æ¨¡å‹åç¨±
        batch_size: æ‰¹æ¬¡æ•¸é‡
        image_files: åœ–ç‰‡æª”åæ˜ å°„ {"source": "xxx.png", "target": "yyy.png"}
        audio_file: éŸ³è¨Šæª”å (ç”¨æ–¼ virtual_human å·¥ä½œæµ)
    
    Returns:
        ä¿®æ”¹å¾Œçš„ workflow dict
    """
    if image_files is None:
        image_files = {}
    if prompts is None:
        prompts = []
    # è¼‰å…¥åŸå§‹ workflow
    workflow = load_workflow(workflow_name)
    workflow = copy.deepcopy(workflow)  # é¿å…ä¿®æ”¹åŸå§‹è³‡æ–™
    
    # Veo3 Long Video ç‰¹æ®Šè™•ç†ï¼šæ ¹æ“šåœ–ç‰‡æ•¸é‡å‹•æ…‹è£å‰ªå·¥ä½œæµ
    if workflow_name == "veo3_long_video":
        workflow = trim_veo3_workflow(workflow, image_files)
    
    # å–å¾—è§£æåº¦
    resolution = ASPECT_RATIO_MAP.get(aspect_ratio, DEFAULT_RESOLUTION)
    width = resolution["width"]
    height = resolution["height"]
    
    # è™•ç† seed (-1 è¡¨ç¤ºéš¨æ©Ÿ)
    if seed == -1:
        import random
        seed = random.randint(0, 2**32 - 1)
    
    print(f"[Parser] è§£æåº¦: {width}x{height}, Seed: {seed}, Model: {model}")
    
    # ==========================================
    # æ³¨å…¥ Prompt (æ”¯æ´å¤šç¨®ç¯€é»é¡å‹)
    # ==========================================
    prompt_injected = False
    
    # 1. å˜—è©¦ CLIPTextEncode (æ¨™æº– SDXL workflow)
    positive_nodes = find_nodes_by_class(workflow, "CLIPTextEncode")
    for node_id, node in positive_nodes:
        title = node.get("_meta", {}).get("title", "")
        if "Positive" in title or "positive" in title.lower():
            node["inputs"]["text"] = prompt
            print(f"[Parser] æ³¨å…¥ Prompt åˆ° CLIPTextEncode ç¯€é» {node_id}")
            prompt_injected = True
            break
    else:
        # å¦‚æœæ²’æ‰¾åˆ°æ¨™é¡Œï¼Œå˜—è©¦ç¬¬ä¸€å€‹ CLIPTextEncode
        if positive_nodes:
            positive_nodes[0][1]["inputs"]["text"] = prompt
            print(f"[Parser] æ³¨å…¥ Prompt åˆ°ç¬¬ä¸€å€‹ CLIPTextEncode ç¯€é»")
            prompt_injected = True
    
    # 2. å˜—è©¦ StringConstantMultiline (ç”¨æ–¼ face_swap ç­‰éœ€è¦ç”¨æˆ¶è¼¸å…¥çš„ workflow)
    # æ³¨æ„ï¼šä¸è¦æ³¨å…¥åˆ° title åŒ…å« "Trigger" æˆ– "trigger" çš„ç¯€é»ï¼Œé‚£äº›æ˜¯é è¨­å…§å®¹
    if not prompt_injected:
        string_nodes = find_nodes_by_class(workflow, "StringConstantMultiline")
        for node_id, node in string_nodes:
            title = node.get("_meta", {}).get("title", "").lower()
            # è·³éåŒ…å« trigger çš„ç¯€é»ï¼ˆé‚£æ˜¯é è¨­å›ºå®šçš„ promptï¼‰
            if "trigger" not in title:
                if "inputs" in node and "string" in node["inputs"]:
                    node["inputs"]["string"] = prompt
                    print(f"[Parser] æ³¨å…¥ Prompt åˆ° StringConstantMultiline ç¯€é» {node_id} (title: {node.get('_meta', {}).get('title', '')})")
                    prompt_injected = True
                    break
    
    # 3. å˜—è©¦ TextEncodeQwenImageEditPlus (Qwen Image Edit workflow)
    if not prompt_injected:
        qwen_nodes = find_nodes_by_class(workflow, "TextEncodeQwenImageEditPlus")
        for node_id, node in qwen_nodes:
            title = node.get("_meta", {}).get("title", "").lower()
            # åªæ³¨å…¥åˆ° Positive ç¯€é» (é€šå¸¸ Negative ç¯€é»çš„ prompt ç‚ºç©º)
            if "negative" not in title:
                if "inputs" in node and "prompt" in node["inputs"]:
                    node["inputs"]["prompt"] = prompt
                    print(f"[Parser] æ³¨å…¥ Prompt åˆ° TextEncodeQwenImageEditPlus ç¯€é» {node_id}")
                    prompt_injected = True
                    break
        
        if not prompt_injected and qwen_nodes:
            # å¦‚æœæ‰¾ä¸åˆ°æ˜ç¢ºçš„ Positiveï¼Œå˜—è©¦ç¬¬ä¸€å€‹æœ‰ prompt è¼¸å…¥çš„ç¯€é»
            for node_id, node in qwen_nodes:
                if "inputs" in node and "prompt" in node["inputs"]:
                    # æª¢æŸ¥é€™å€‹ç¯€é»çš„ prompt æ˜¯å¦ä¸ç‚ºç©º (è¡¨ç¤ºæ˜¯ Positive)
                    if node["inputs"]["prompt"] or node["inputs"]["prompt"] == "":
                        node["inputs"]["prompt"] = prompt
                        print(f"[Parser] æ³¨å…¥ Prompt åˆ° TextEncodeQwenImageEditPlus ç¯€é» {node_id} (fallback)")
                        prompt_injected = True
                        break
    
    if not prompt_injected:
        print(f"[Parser] âš ï¸ æœªæ‰¾åˆ°å¯æ³¨å…¥ Prompt çš„ç¯€é»")
    
    # ==========================================
    # Veo3 Long Video: æ³¨å…¥å¤šæ®µ Prompts (Strategy B)
    # é—œéµï¼šè¿­ä»£ Config çš„ prompt_segmentsï¼Œè€Œéç”¨æˆ¶è¼¸å…¥
    # ==========================================
    # æª¢æŸ¥ workflow_name æ˜¯å¦æœ‰ prompt_segments é…ç½®
    from config import WORKFLOW_CONFIG_PATH
    import json
    
    config_path = WORKFLOW_CONFIG_PATH
    if config_path.exists():
        with open(config_path, 'r', encoding='utf-8') as f:
            config_data = json.load(f)
        
        workflow_config = config_data.get(workflow_name, {})
        mapping = workflow_config.get('mapping', {})
        prompt_segments_config = mapping.get('prompt_segments', {})
        
        if prompt_segments_config:
            print(f"[Parser] æª¢æ¸¬åˆ° prompt_segments é…ç½®ï¼Œé–‹å§‹æ³¨å…¥ {len(prompt_segments_config)} å€‹ç‰‡æ®µ...")
            
            # Strategy B: è¿­ä»£ Config å®šç¾©çš„ segments
            injected_count = 0
            skipped_count = 0
            for segment_index_str, node_id_str in prompt_segments_config.items():
                segment_index = int(segment_index_str)
                
                # å„ªå…ˆæª¢æŸ¥ç¯€é»æ˜¯å¦ä»å­˜åœ¨æ–¼å·¥ä½œæµä¸­ï¼ˆå¯èƒ½å·²è¢«å‹•æ…‹è£å‰ªåˆªé™¤ï¼‰
                if node_id_str not in workflow:
                    print(f"[Parser] â­ï¸ è·³éå·²åˆªé™¤çš„ç¯€é» {node_id_str} (segment {segment_index})")
                    skipped_count += 1
                    continue
                
                # æª¢æŸ¥ç”¨æˆ¶æ˜¯å¦æä¾›äº†è©² segment çš„ prompt
                if segment_index < len(prompts) and prompts[segment_index]:
                    user_prompt = prompts[segment_index]
                else:
                    # ç”¨æˆ¶æœªæä¾›æˆ–ç•™ç©ºï¼Œä½¿ç”¨ç©ºå­—ä¸²
                    user_prompt = ""
                
                print(f"[Parser] Segment {segment_index}: Node {node_id_str} = '{user_prompt[:40] if user_prompt else '(empty)'}...'")
                
                # æ³¨å…¥åˆ°å°æ‡‰ç¯€é»
                node = workflow[node_id_str]
                
                # å„ªå…ˆå˜—è©¦ inputs.promptï¼ˆComfyUI API æ ¼å¼ï¼‰
                if 'inputs' in node and isinstance(node['inputs'], dict):
                    if 'prompt' in node['inputs']:
                        node['inputs']['prompt'] = user_prompt
                        print(f"[Parser] âœ“ å·²æ³¨å…¥åˆ° Node {node_id_str}.inputs.prompt")
                        injected_count += 1
                
                # å˜—è©¦ widgets_values (èˆŠç‰ˆæ ¼å¼)
                elif 'widgets_values' in node:
                    if isinstance(node['widgets_values'], list) and len(node['widgets_values']) > 0:
                        node['widgets_values'][0] = user_prompt
                        injected_count += 1
                    elif isinstance(node['widgets_values'], dict) and 'prompt' in node['widgets_values']:
                        node['widgets_values']['prompt'] = user_prompt
                        injected_count += 1
            
            print(f"[Parser] âœ… å®Œæˆ prompt segments æ³¨å…¥: {injected_count} å€‹æˆåŠŸ, {skipped_count} å€‹è·³é")
    
    # ==========================================
    # æ³¨å…¥ Seed (KSampler)
    # ==========================================
    sampler_id, sampler_node = find_node_by_class(workflow, "KSampler")
    if sampler_node:
        sampler_node["inputs"]["seed"] = seed
        print(f"[Parser] æ³¨å…¥ Seed åˆ° KSampler ç¯€é» {sampler_id}")
    
    # ==========================================
    # æ³¨å…¥ Resolution (EmptySD3LatentImage / EmptyLatentImage)
    # ==========================================
    latent_classes = ["EmptySD3LatentImage", "EmptyLatentImage"]
    for class_type in latent_classes:
        latent_id, latent_node = find_node_by_class(workflow, class_type)
        if latent_node:
            latent_node["inputs"]["width"] = width
            latent_node["inputs"]["height"] = height
            latent_node["inputs"]["batch_size"] = batch_size
            print(f"[Parser] æ³¨å…¥è§£æåº¦ {width}x{height} åˆ° {class_type} ç¯€é» {latent_id}")
            break
    
    # ==========================================
    # æ³¨å…¥ Model (UNETLoader / CheckpointLoaderSimple)
    # ==========================================
    model_filename = MODEL_MAP.get(model)
    
    if model_filename:
        # å˜—è©¦ UNETLoader
        unet_id, unet_node = find_node_by_class(workflow, "UNETLoader")
        if unet_node:
            unet_node["inputs"]["unet_name"] = model_filename
            print(f"[Parser] æ³¨å…¥æ¨¡å‹ {model_filename} åˆ° UNETLoader ç¯€é» {unet_id}")
        
        # å˜—è©¦ CheckpointLoaderSimple
        ckpt_id, ckpt_node = find_node_by_class(workflow, "CheckpointLoaderSimple")
        if ckpt_node:
            ckpt_node["inputs"]["ckpt_name"] = model_filename
            print(f"[Parser] æ³¨å…¥æ¨¡å‹ {model_filename} åˆ° CheckpointLoaderSimple ç¯€é» {ckpt_id}")
    else:
        print(f"[Parser] âš ï¸ æœªçŸ¥æ¨¡å‹: {model}ï¼Œä½¿ç”¨ workflow é è¨­å€¼")
    
    # ==========================================
    # æ³¨å…¥åœ–ç‰‡ (LoadImage ç¯€é»)
    # ==========================================
    node_map = IMAGE_NODE_MAP.get(workflow_name, {})
    
    if node_map and image_files:
        print(f"[Parser] æº–å‚™æ³¨å…¥åœ–ç‰‡ï¼Œæ˜ å°„è¡¨: {node_map}")
        print(f"[Parser] æ”¶åˆ°çš„åœ–ç‰‡æª”æ¡ˆ: {image_files}")
        
        for node_id, field_name in node_map.items():
            if field_name in image_files:
                filename = image_files[field_name]
                
                # æ‰¾åˆ°å°æ‡‰çš„ LoadImage ç¯€é»
                if node_id in workflow:
                    node = workflow[node_id]
                    if "inputs" in node:
                        old_image = node["inputs"].get("image", "")
                        node["inputs"]["image"] = filename
                        print(f"[Parser] âœ… ç¯€é» {node_id}: {old_image!r} -> {filename!r}")
                    else:
                        print(f"[Parser] âš ï¸ ç¯€é» {node_id} æ²’æœ‰ inputs")
                else:
                    print(f"[Parser] âš ï¸ æ‰¾ä¸åˆ°ç¯€é» {node_id}")
            else:
                print(f"[Parser] âš ï¸ ç¼ºå°‘åœ–ç‰‡æ¬„ä½: {field_name}")
    elif node_map:
        print(f"[Parser] âš ï¸ æ­¤å·¥ä½œæµéœ€è¦åœ–ç‰‡ä½†æœªæä¾›: {list(node_map.values())}")
    
    # ==========================================
    # æ³¨å…¥éŸ³è¨Š (LoadAudio ç¯€é») - Phase 7 æ–°å¢
    # ==========================================
    audio_config = AUDIO_NODE_MAP.get(workflow_name)
    
    if audio_config and audio_file:
        node_id = audio_config.get("node_id")
        input_key = audio_config.get("input_key", "audio")
        
        if node_id and node_id in workflow:
            node = workflow[node_id]
            if "inputs" in node:
                old_audio = node["inputs"].get(input_key, "")
                node["inputs"][input_key] = audio_file
                print(f"[Parser] ğŸµ Injecting audio file: {audio_file} into node {node_id}")
                print(f"[Parser] âœ… éŸ³è¨Šç¯€é» {node_id}: {old_audio!r} -> {audio_file!r}")
            else:
                print(f"[Parser] âš ï¸ éŸ³è¨Šç¯€é» {node_id} æ²’æœ‰ inputs")
        elif node_id:
            print(f"[Parser] âš ï¸ æ‰¾ä¸åˆ°éŸ³è¨Šç¯€é» {node_id}")
    elif audio_config and not audio_file:
        print(f"[Parser] â„¹ï¸ å·¥ä½œæµ {workflow_name} æ”¯æ´éŸ³è¨Šæ³¨å…¥ï¼Œä½†æœªæä¾›éŸ³è¨Šæª”æ¡ˆï¼Œä½¿ç”¨é è¨­å€¼")
    
    return workflow


# ==========================================
# æ¸¬è©¦ç”¨
# ==========================================
if __name__ == "__main__":
    # æ¸¬è©¦ parse_workflow
    try:
        workflow = parse_workflow(
            workflow_name="text_to_image",
            prompt="A beautiful sunset over mountains",
            seed=12345,
            aspect_ratio="16:9",
            model="turbo_fp8",
            batch_size=1
        )
        print("\n[Test] Workflow è§£ææˆåŠŸï¼")
        print(json.dumps(workflow, indent=2, ensure_ascii=False)[:500] + "...")
    except Exception as e:
        print(f"[Test] éŒ¯èª¤: {e}")
